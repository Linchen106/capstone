{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1. Setup](#Setup)\n",
    "\n",
    "[2. Data Cleaning and Preparation](#Data-Cleaning-&-Preparation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import basic system functions\n",
    "import os\n",
    "import datetime\n",
    "from collections import Counter\n",
    "\n",
    "#import libraries for data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import libraries for plotting data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as mplt\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "\n",
    "\n",
    "#import libraries for time series analysis\n",
    "#from fbprophet import Prophet\n",
    "from pylab import rcParams\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "#import libraries for statistics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "#from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df= pd.read_csv(\"/Users/brittarover/Capstone/Meteolytics/meteolytix_Artikelgruppen_Umsatz_verschiedeneStandorte.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify Dataframe to define the labels as columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**\n",
    "- `To analyse the single labels, the different articlegroups, the dataframe needs to be restructured by using a pivot table. The result is a dataframe with one single column per articlegroup which can be used for prediction.`\n",
    "- `To consider the different closed days for the filialen / stores i do it in a second step separatly for the stores.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=pd.pivot_table(df, values='Umsatz', index=['Datum','Filiale'],columns=['Artikelgruppe'], \n",
    "                        aggfunc=np.sum, fill_value=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty dataframe with 'complete' datetime index\n",
    "date_df = pd.DataFrame(index=pd.date_range(start='1/1/2015', end=df.Datum.max()))\n",
    "df_new_1 = pd.pivot_table(df[df.Filiale == 1], values='Umsatz', index=['Datum'],columns=['Artikelgruppe'], \n",
    "                        aggfunc=np.sum, fill_value=0)\n",
    "#fill missing days due to store closings with 0 \n",
    "df_new_1=df_new_1.merge(date_df, how='right', left_index= True,right_index=True).fillna(0)\n",
    "df_new_1.index = df_new_1.index.set_names(['Datum'])\n",
    "df_new_1=df_new_1.reset_index()\n",
    "\n",
    "df_new_2 = pd.pivot_table(df[df.Filiale == 2], values='Umsatz', index=['Datum'],columns=['Artikelgruppe'], \n",
    "                        aggfunc=np.sum, fill_value=0)\n",
    "#fill missing days due to store closings with 0 \n",
    "df_new_2 = df_new_2.merge(date_df, how='right',left_index= True,right_index=True).fillna(0)\n",
    "df_new_2.index = df_new_2.index.set_names(['Datum'])\n",
    "df_new_2=df_new_2.reset_index()\n",
    "\n",
    "df_new_3 = pd.pivot_table(df[df.Filiale == 3], values='Umsatz', index=['Datum'],columns=['Artikelgruppe'], \n",
    "                        aggfunc=np.sum, fill_value=0)\n",
    "#fill missing days due to store closings with 0 \n",
    "df_new_3 = df_new_3.merge(date_df, how='right',left_index= True,right_index=True).fillna(0)\n",
    "df_new_3.index = df_new_3.index.set_names(['Datum'])\n",
    "df_new_3=df_new_3.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Warengruppeninfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**\n",
    "- `I introduce Warengruppen given by meterolytics to give an better overall picture to the sales trends.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Warenguppeninfo\n",
    "df['Warengruppe']=df['Artikelgruppe'].apply(lambda x: \"Brot\" if x in (1,2,3,4,5) else \"Brötchen\" if x in (6,7) \n",
    "                                            else \"Spezial_Brötchen\" if x==8 else\n",
    "                                              \"Konditorei\" if x in (9,10) else \"Kuchen\" if x in (11,12) else \"Weihnachtsartikel\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_waren = pd.pivot_table(df, values='Umsatz', index=['Datum','Filiale'],\n",
    "                    columns=['Warengruppe'], aggfunc=np.sum, fill_value=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming Artikelgruppe for all new dataframes\n",
    "list=[df_new,df_new_1,df_new_2,df_new_3,df_new_waren]\n",
    "\n",
    "for i in list:\n",
    "  i.rename(columns={1:'Weizenbrot',2:\"Mischbrot\",3:'Vollkornbrot',4:\"Stangenbrote\",5:\"Spezialbrot\",6 : \"Brötchen\",\n",
    "                       7 : \"Süsse_Brötchen\",8 :\"Herzhafte_Brötchen\",9 : \"KonditoreiBlech1\",10: \"KonditoreiBlech2\",\n",
    "                       11: \"Stückgebäck\", 12:\"Blechkuchen\",13 : \"Weihnachtsartikel\"\n",
    "                          }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_1.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a Gesamt Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a Gesamt column to all the new dataframes which contains the total sales\n",
    "list=[df_new,df_new_1,df_new_2,df_new_3]\n",
    "\n",
    "for i in list:\n",
    "    i['Gesamt']=i['Vollkornbrot']+i['Mischbrot']+i['Stangenbrote']+i['Weizenbrot']+i['Spezialbrot']+i['Brötchen']\n",
    "    +i['Süsse_Brötchen']+i['Herzhafte_Brötchen']+i['KonditoreiBlech1']+i['KonditoreiBlech2']+i['Blechkuchen']\n",
    "    +i['Weihnachtsartikel']+i['Stückgebäck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Columns Definition\n",
    "\n",
    "- **Filiale** - There are three different filial stores which are analyzed, one direct in the city (filiale=1), one near the water front (filiale=2) and the third in a residential area (filiale=3)\n",
    "1 = city; 2 = waterfront area; 3 = city disctrict\n",
    "- **Datum** - date of the sales data. The period \n",
    "- **Warengruppe** - main article group\n",
    "1 = Brot; 2 = Brötchen; 3 = Spezial_Brötchen; 4 = Konditorei; 5 = Kuchen; 6 = Weihnachtsartikel    \n",
    "- **Artikelgruppe** - article group\n",
    "1 = Weizenbrot; 2 = Mischbrot; 3 = Vollkornbrot; 4 = Spezialbrot; 5 = Stangenbrote; 6 = Brötchen; 7 = Süße Brötchen; 8 = Herzhafte Brötchen; 9 = KonditoreiBlech1; 10 = KonditoreiBlech2; 11 = Stückgebäck; 12 = Blechkuchen; 13 = Weiohnachtsartikel;     \n",
    "- **Umsatz** - Sales volumne per day and article group   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dtypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical insights of the new dataframe\n",
    "df_new.describe().round(2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate count statistics of duplicate entries\n",
    "if len(df[df.duplicated()]) > 0:\n",
    "    print(\"No. of duplicated entries: \", len(df[df.duplicated()]))\n",
    "    print(df[df.duplicated(keep=False)].sort_values(by=list(df.columns)).head())\n",
    "else:\n",
    "    print(\"No duplicated entries found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions Distribution**\n",
    "- `There are not so many sales values for Filiale 1 than for the two other Filialen. This is due to the fact that the Filiale is not openend on sundays regulary. The Filiale is openend on every 1. sunday of a month except in february, but there a quite a few exceptions to this rule: weekends during Kieler Woche in june, verkaufsoffene Sonntage and the last sunday in september. Is the first sunday a public selebration day the Filiale is opened on the second sunday of a month.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at data skew; the skewness of values along an axis, returning 0 where all values are equal or if they follow \n",
    "# a normal distribution\n",
    "skew_gesamt=df_new.skew()\n",
    "skew_Filiale_1=df_new_1.skew()\n",
    "skew_Filiale_2=df_new_2.skew()\n",
    "skew_Filiale_3=df_new_3.skew()\n",
    "\n",
    "skew_total = pd.concat([skew_Filiale_1,skew_Filiale_2, skew_Filiale_3,skew_gesamt],axis=1)\n",
    "skew_total.rename(columns={0:'Filiale_1',1:'Filiale_2',2:'Filiale_3',3:'Gesamt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution for single Filialen and all\n",
    "# Number of unique values for each column, sorted by count for the whole data set and for the single Filialen\n",
    "\n",
    "distr_Filiale_1=df_new_1.T.apply(lambda x: x.nunique(), axis=1).sort_values(ascending=False)\n",
    "distr_Filiale_2=df_new_2.T.apply(lambda x: x.nunique(), axis=1).sort_values(ascending=False)\n",
    "distr_Filiale_3=df_new_3.T.apply(lambda x: x.nunique(), axis=1).sort_values(ascending=False)\n",
    "distr_total=df_new.T.apply(lambda x: x.nunique(), axis=1).sort_values(ascending=False)\n",
    " \n",
    "distr_total = pd.concat([distr_Filiale_1,distr_Filiale_2, distr_Filiale_3,distr_total],axis=1)\n",
    "distr_total.rename(columns={0:'Filiale_1',1:'Filiale_2',2:'Filiale_3',3:'Gesamt'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning & Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation to Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation to Datetime\n",
    "list=[df,df_new,df_new_1,df_new_2,df_new_3,df_new_waren]\n",
    "\n",
    "for i in list:\n",
    "  i['Datum'] = pd.to_datetime(i['Datum'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Date columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list:\n",
    "   i['Wochentag']=i['Datum'].dt.weekday\n",
    "   i['Jahr']=i['Datum'].dt.year\n",
    "   i['Monat']=i['Datum'].dt.month\n",
    "   i['Wochenende']=i['Wochentag'].apply(lambda x: 'Wochentag' if x in (0,1,2,3,4) else 'Wochenende')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Negative Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions Negative sales values**\n",
    "- `There are in total 166 negative sales values. Affected are Artikelgruppe 5, 2 and 10.`\n",
    "- `Maybe the negative values arise from unsold articles which can not be further processed or to corrections on previous values.`\n",
    "- `I decide to skip these values. The easiest way to do is to do it before transformation.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for negative Values\n",
    "df_neg_Umsatz=df.query('Umsatz<0')\n",
    "df_neg_Umsatz.Artikelgruppe.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions Null values**\n",
    "- `The check does not show any  missing values due to the fact that exactly one row exists per sales`\n",
    "- `But the df.describe / df.artikelgruppe.mean shows that are a lot of days with less than 13 entries. This was handled by transformation of the dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking null values\n",
    "nan = pd.DataFrame(df_new.isnull().sum(),columns=['Count'])\n",
    "nan['Percentage'] = round(nan.Count/df.shape[0]*100,1)\n",
    "print(nan[nan.Count!=0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check openingdates for Filialen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summe=df.groupby(['Filiale','Datum']).Umsatz.count().reset_index()\n",
    "df_summe=pd.pivot_table(df_summe,values='Umsatz',index=['Datum'],columns='Filiale',fill_value=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summe['Wochentag']=df_summe['Datum'].dt.weekday\n",
    "df_summe['Jahr']=df_summe['Datum'].dt.year\n",
    "\n",
    "df_summe.rename(columns={1: 'Filiale_1', 2: 'Filiale_2', 3: 'Filiale_3'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filiale 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=df_new_1.Gesamt.count()\n",
    "days_sunday=df_new_1.query('Wochentag==6').Gesamt.count()\n",
    "closed_1_sun=df_new_1.query('Wochentag==6 and Gesamt==0').Gesamt.count()\n",
    "closed_1=df_new_1.query('Gesamt==0').Gesamt.count()\n",
    "closed_1_2019=df_new_1.query('Gesamt==0 and Jahr==2019').Gesamt.count()\n",
    "percent=(closed_1_sun/days_sunday*100)\n",
    "percent=percent.round(2)\n",
    "\n",
    "\n",
    "print(f\"Filiale 1 is closed on {closed_1}  of {days} days in total in the period. \")\n",
    "print(f\"This is due to the fact that the Filiale is closed on {closed_1_sun} sundays. This are {percent} % of all sundays.\")\n",
    "print(f\"The most closed days {closed_1_2019} are in 2019. The Filiale is totally closed from the 18.01.2019 until the 06.02.2019.\")     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filiale 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_2=df_new_2.query('Gesamt==0').Gesamt.count()\n",
    "closed_2_avg=closed_2/5.418207\n",
    "closed_2_avg=closed_2_avg.round(0).astype(int)\n",
    "closed_2_avg\n",
    "\n",
    "print(f\"Filiale 2 is closed on {closed_2}  of {days} days in total in the period.\")\n",
    "print(f\"This means the Filiale is closed in average on {closed_2_avg} days per year.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filiale 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_3=df_new_3.query('Gesamt==0').Gesamt.count()\n",
    "closed_3_avg=closed_3/5.418207\n",
    "closed_3_avg=closed_3_avg.round(0).astype(int)\n",
    "closed_3_avg\n",
    "\n",
    "print(f\"Filiale 3 is closed on {closed_3}  of {days} days in total in the period.\")\n",
    "print(f\"This means the Filiale is closed in average on {closed_3_avg} days per year.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check sales for articlegroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions Missing values Filiale 1**\n",
    "-`Weihnachtsartikel are not sold on more as 85 % of all the days.`\n",
    "-`Weizenbrot is not sold on more as 90 % of all the sundays.`\n",
    "- `KonditoreiBlech2 is not sold on more than 40 % of every day, KonditoreiBlech is not on in allmost 7 % of all dates`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions Missing values Filiale 2**\n",
    "-`Weihnachtsartikel are not sold on more as 85 % of all the days.`\n",
    "- `Weizenbrot is not sold on more as 90 % of all the sundays.`\n",
    "- `KonditoreiBlech2 is not sold on more than 44 % of every day, KonditoreiBlech is not on in allmost 7 % of all dates`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions Missing values Filiale 3**\n",
    "-`Weihnachtsartikel are not sold on more as 85 % of all the days.`\n",
    "- `KonditoreiBlech2 is not sold on more than 70 % of every day, KonditoreiBlech is not on in allmost 7 % of all dates`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt=pd.melt(frame=df_new.iloc[:,0:15],id_vars=['Datum','Filiale'],var_name='Artikelgruppe',value_name='Umsatz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis for Filiale 1\n",
    "zero_1=df_melt.query('Umsatz==0 and Filiale==1').groupby(['Filiale','Artikelgruppe']).Umsatz.count().reset_index()\n",
    "zero_1['Prozent']=(zero_1[\"Umsatz\"]/1662)*100\n",
    "zero_1.nlargest(5, 'Prozent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt['Wochentag']=df_melt['Datum'].dt.weekday\n",
    "zero_1b=df_melt.query('Umsatz==0 and Filiale==1 and Artikelgruppe in (\"Weizenbrot\",\"KonditoreiBlech1\",\"KonditoreiBlech2\")').groupby(['Filiale','Artikelgruppe','Wochentag']).Umsatz.count().reset_index()\n",
    "zero_1b['Summe_offen']=zero_1b[\"Wochentag\"].apply(lambda x: 267 if x in (0,1,2,3,4,5) else 62)\n",
    "zero_1b['Prozent']=zero_1b['Umsatz']*100/zero_1b['Summe_offen']\n",
    "zero_1b.nlargest(5, 'Prozent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis for Filiale 2\n",
    "zero_2=df_melt.query('Umsatz==0 and Filiale==2').groupby(['Filiale','Artikelgruppe']).Umsatz.count().reset_index()\n",
    "zero_2['Prozent']=(zero_2[\"Umsatz\"]/1934)*100\n",
    "zero_2.nlargest(5, 'Prozent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt['Wochentag']=df_melt['Datum'].dt.weekday\n",
    "zero_2b=df_melt.query('Umsatz==0 and Filiale==2 and Artikelgruppe in (\"Weizenbrot\",\"KonditoreiBlech1\",\"KonditoreiBlech2\")').groupby(['Filiale','Artikelgruppe','Wochentag']).Umsatz.count().reset_index()\n",
    "zero_2b['Summe_offen']=267\n",
    "zero_2b['Prozent']=zero_2b['Umsatz']*100/zero_2b['Summe_offen']\n",
    "zero_2b.nlargest(1, 'Prozent') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis for Filiale 3\n",
    "zero_3=df_melt.query('Umsatz==0 and Filiale==2').groupby(['Filiale','Artikelgruppe']).Umsatz.count().reset_index()\n",
    "zero_3['Prozent']=(zero_3[\"Umsatz\"]/1933)*100\n",
    "zero_3.nlargest(5, 'Prozent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### New Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Total level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**\n",
    "- `There are a lot of stronger correlations between the Filiale and the single Artikelgruppen.`\n",
    "- `There are also a lot of stronger correlations between the Artikelgruppen itself.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we create a new DataFrame with only numerical features\n",
    "numerics = ['int64', 'float64']\n",
    "\n",
    "num_df = df_new.select_dtypes(include=numerics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Korrelationsanalyse\n",
    "mask = np.triu( num_df.corr())\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.title('Correlation of variables')\n",
    "ax=sns.heatmap(num_df.corr(),vmax=1.0,annot=True,mask=mask,cmap='coolwarm')\n",
    "plt.savefig('correlogram_simple.png')\n",
    "ax.set_ylim((0,18))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Filiale level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['int64', 'float64']\n",
    "num_Filiale_1 = df_new_1.select_dtypes(include=numerics)\n",
    "num_Filiale_2 = df_new_2.select_dtypes(include=numerics)\n",
    "num_Filiale_3 = df_new_1.select_dtypes(include=numerics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Korrelationsanalyse FILIALE 1\n",
    "mask = np.triu(num_Filiale_1.corr())\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.title('Correlation of variables')\n",
    "ax=sns.heatmap(num_Filiale_1.corr(),vmax=1.0,annot=True,mask=mask,cmap='coolwarm')\n",
    "plt.savefig('correlogram_simple.png')\n",
    "ax.set_ylim((0,18))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Korrelationsanalyse FILIALE 2\n",
    "mask = np.triu( num_Filiale_2.corr())\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.title('Correlation of variables')\n",
    "ax=sns.heatmap(num_Filiale_2.corr(),vmax=1.0,annot=True,mask=mask,cmap='coolwarm')\n",
    "plt.savefig('correlogram_simple.png')\n",
    "ax.set_ylim((0,18))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Korrelationsanalyse FILIALE 3\n",
    "mask = np.triu( num_Filiale_3.corr())\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.title('Correlation of variables')\n",
    "ax=sns.heatmap(num_Filiale_3.corr(),vmax=1.0,annot=True,mask=mask,cmap='coolwarm')\n",
    "plt.savefig('correlogram_simple.png')\n",
    "ax.set_ylim((0,18))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore sales for Filiale in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1=df.query('Filiale== 1')\n",
    "df_2=df.query('Filiale== 2')\n",
    "df_3=df.query('Filiale== 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_wg1=df_new_waren.query('Filiale==1')\n",
    "df_new_wg2=df_new_waren.query('Filiale==2')\n",
    "df_new_wg3=df_new_waren.query('Filiale==3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salestrends per Filiale / Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='Jahr',y='Gesamt',hue='Filiale',data=df_new,estimator='sum')\n",
    "plt.title('Revenue per store and year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filiale 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions FILIALE 1**\n",
    "- `Sales in total are relatively constant. In March 2020 Corona starts..`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing and resampling of the dataframe\n",
    "df_index = df.set_index('Datum')\n",
    "\n",
    "y_1 = df_index['Umsatz'].loc[df_index['Filiale'] == 1].resample('D').mean()\n",
    "y_1.plot(figsize=(15, 6))\n",
    "\n",
    "plt.show\n",
    "\n",
    "#ax=fig.add_subplot(1,1,1)\n",
    "#'crisis_data=[\n",
    "#    (datetime(2020,3,17)-'Start Lockdown Corona'),\n",
    "#    (datetime(2020,4,20)-'End Lockdown Corona'),\n",
    "#    (datetime(2020,3,17)-'End of the Beherbergungsverbot in Schleswig Holstein')\n",
    "#]\n",
    "#for date, label in crisis_data:\n",
    "#    ax.annotate(label,xy=(date,y_1.asof(date)+75),\n",
    "#                xytext=(date,y_1.asof(date)+225),\n",
    "#                arrowprops=dict(facecolor='black',headwidth=4,width=2,headlength=4),\n",
    "#                horizontalalignment='left',verticalalignment='top')\n",
    "#ax.set_title('Sales trend in total for Filiale 1')    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.loc[df_1['Umsatz'].idxmax()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales on Months and Weekdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revenue per Filiale 1 and Month\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='Monat',y='Gesamt',data=df_new_1,estimator='mean',color='indianred')\n",
    "plt.xlabel(\"Month starting with January\", fontsize=12)\n",
    "plt.ylabel(\"Average Salesamount\", fontsize=12)\n",
    "plt.title('Revenue per Filiale 1 and Month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revenue per Filiale 2 and Weekday\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='Wochentag',y='Gesamt',data=df_new_1,estimator='mean',color='indianred')\n",
    "plt.xlabel(\"Weekday starting with Monday\", fontsize=12)\n",
    "plt.ylabel(\"Average Salesamount\", fontsize=12)\n",
    "plt.title('Revenue per Filiale 1 and Weekday')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filiale 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions FILIALE 2**\n",
    "- `Sales in total are relatively constant over the years.`\n",
    "- `But there is a strong seasonal effect. During summertime they are higher sales for all the years`\n",
    "- `There is also a weekday effect, but not a strong one. The values are a bit higher for saturdays and sundays. The lowest values are on wednesdays. Kiel is a attractive holiday destination for extended weekendtrips.\n",
    "`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2 = df_index['Umsatz'].loc[df_index['Filiale'] == 2].resample('D').mean()\n",
    "y_2.plot(figsize=(15, 6))\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales on Months and Weekdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Revenue per Filiale 2 and Month \n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='Monat',y='Gesamt',data=df_new_2,estimator='mean',color='coral')\n",
    "plt.xlabel(\"Month starting with January\", fontsize=12)\n",
    "plt.ylabel(\"Average Salesamount\", fontsize=12)\n",
    "plt.title('Revenue per Filiale 2 and Month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_2=pd.pivot_table(df_2,index=df['Datum'].dt.month,columns=df['Datum'].dt.year,\n",
    "               values='Umsatz',aggfunc=np.sum).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot_2.pct_change().nlargest(5,2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revenue per Filiale 2 and Weekday\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='Wochentag',y='Gesamt',data=df_new_2,estimator='sum',color='coral')\n",
    "plt.xlabel(\"Weekday starting with Monday\", fontsize=12)\n",
    "plt.ylabel(\"Average Salesamount\", fontsize=12)\n",
    "plt.title('Average Revenue per Filiale 2 and Weekday', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filiale 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions FILIALE 3**\n",
    "- `Sales values in total are relatively constant over the years until Corona starts in march 2020..`\n",
    "- `But there is a strong relationsship between weekday and over-all salesvalue. For weekends the values are significant higher. This is valid for all the years.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_3 = df_index['Umsatz'].loc[df_index['Filiale'] == 3].resample('D').mean()\n",
    "y_3.plot(figsize=(15, 6))\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales on Months and Weekdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revenue per Filiale 3 and Month\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='Monat',y='Gesamt',data=df_new_3,estimator='mean')\n",
    "plt.xlabel(\"Month starting with January\", fontsize=12)\n",
    "plt.ylabel(\"Average Salesamount\", fontsize=12)\n",
    "plt.title('Revenue per Filiale 3 and Month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revenue per Filiale 3 and Weekday\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='Wochentag',y='Gesamt',data=df_new_3,estimator='mean')\n",
    "plt.xlabel(\"Weekday starting with Monday\", fontsize=12)\n",
    "plt.ylabel(\"Average Salesamount\", fontsize=12)\n",
    "plt.title('Average Revenue per Filiale 3 and Weekday', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salestrends per Filiale and Articles (Artikel- and Warengruppen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chapter deals with the different articlegroups and their different behaviour over the time. These analysis is completed by the linked **Notebook with histogramms and boxplots** for each articlegroup/store combination.\n",
    "Special analysis for Timeseries can be found in the chapter **Checks Timeseries**. This chapter deals with Autocorrelation Plots (AC and PAC), Stationarity Checks .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Additional Graphics on articelgroups](./capstone_boxplots_EDA.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Checks Timeseries](#Checks-Timeseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filiale 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions FILIALE 1**\n",
    "- `Sales in total are relatively constant.`\n",
    "- `There exist stronger seasonals effects for the following articlegroups: Weihnachtsartikel and Blechkuchen (saisonality type: yearly). All the other groups have a weekly saisonaliyty that means a autocorrelation peak at a lag of 1 week.`\n",
    " \n",
    "- `The highest Salesvolumne per Artikelgruppe was 1091,65€ for Artikelgruppe 11:= Stückgebäck on New Year's Eve\n",
    "2018, everbody buys Berliner for New Year's Eve.`\n",
    "- `The highest Salesvolumne per Filiale was 4411.73€ with also a hugh salesvolumne at Artikelgruppe 11:= Stückgebäck. On this day was a store reopening, the bakery has been closed for a couple weeks, since the 17th of january.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_new_1.loc[df_new_1['Stückgebäck'].idxmax()]['Stückgebäck'])\n",
    "print(df_new_1.loc[df_new_1['Stückgebäck'].idxmax()].Datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_new_1.loc[df_new_1['Gesamt'].idxmax()]['Gesamt'])\n",
    "print(df_new_1.loc[df_new_1['Gesamt'].idxmax()].Datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check opening day for the begin of 2019\n",
    "#df_new_1.query('Jahr==2019 and (Monat==1)').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales per Warengruppe overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_waren=df_1.groupby(df_1['Warengruppe']).Umsatz.sum().reset_index()\n",
    "#df_1_waren.head()                     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(df_1_waren, values='Umsatz', names='Warengruppe', color_discrete_sequence=px.colors.sequential.RdBu)\n",
    "             #color='Warengruppe',\n",
    "             #color_discrete_map={'Brot':'lightcyan',\n",
    "                                # 'Brötchen':'cyan',\n",
    "                                # 'Spezial_Brötchen':'royalblue',\n",
    "                                 #'Konditorei':'royalblue',\n",
    "                                 #'Kuchen':'darkblue',\n",
    "fig.update_layout(title_text='Split of the salesvolumne for Filiale 1 on Warengruppen', title_x=0.5)             \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales on Weekdays / Weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis for Warengruppen\n",
    "df_1_wg=df_new_wg1.groupby(\"Wochenende\")['Brot','Brötchen','Konditorei','Kuchen',\n",
    "                                         'Spezial_Brötchen','Weihnachtsartikel'].mean().stack().reset_index()\n",
    "df_1_wg.rename(columns={0:'Umsatz'\n",
    "                          }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df_1_wg, x=\"Warengruppe\", y='Umsatz', color='Wochenende',barmode='group',color_discrete_sequence=px.colors.sequential.RdBu, title=\"Weekend sales compared to weekday sales for Filiale 1 on Warengruppen\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_art=df_new_1.query('Gesamt>0').groupby(\"Wochenende\")['Weizenbrot','Mischbrot','Vollkornbrot','Spezialbrot','Stangenbrote',\n",
    "                                        'Brötchen','Süsse_Brötchen','Herzhafte_Brötchen','KonditoreiBlech1','KonditoreiBlech2',\n",
    "                                        'Stückgebäck','Blechkuchen',\n",
    "                                        'Weihnachtsartikel'].mean().stack().reset_index()\n",
    "df_1_art.rename(columns={0:'Umsatz','level_1':'Artikelgruppe'\n",
    "                          }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis for Artikelgruppen\n",
    "\n",
    "fig = px.bar(df_1_art, x=\"Artikelgruppe\", y='Umsatz', color='Wochenende',barmode='group',\n",
    "             color_discrete_sequence=px.colors.sequential.RdBu, title=\"Weekend sales compared to weekday sales for Filiale 1\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_art2=df_new_1.query('Gesamt>0').groupby(\"Wochentag\")['Weizenbrot','Mischbrot','Vollkornbrot','Spezialbrot','Stangenbrote',\n",
    "                                        'Brötchen','Süsse_Brötchen','Herzhafte_Brötchen','KonditoreiBlech1','KonditoreiBlech2',\n",
    "                                        'Stückgebäck','Blechkuchen',\n",
    "                                        'Weihnachtsartikel'].mean().stack().reset_index()\n",
    "df_1_art2.rename(columns={0:'Umsatz','level_1':'Artikelgruppe'\n",
    "                          }, \n",
    "                 inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df_1_art2, x=\"Wochentag\", y='Umsatz', color='Artikelgruppe',barmode='group',\n",
    "             color_discrete_sequence=px.colors.sequential.RdBu, \n",
    "              title=\"Weekday sales compared to each weekday for Filiale 1\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales on Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis on Month per Warengruppe\n",
    "\n",
    "df_1_wg2=df_new_wg1.groupby(\"Monat\")['Brot','Brötchen','Konditorei','Kuchen',\n",
    "                                         'Spezial_Brötchen','Weihnachtsartikel'].mean().stack().reset_index()\n",
    "df_1_wg2.rename(columns={0:'Umsatz'\n",
    "                          }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = px.bar(df_1_wg2, x=\"Monat\", y='Umsatz', color='Warengruppe',barmode='group',\n",
    "#             color_discrete_sequence=px.colors.sequential.RdBu, title=\"average sales compared on month for Filiale 1\")\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis on Month per Artikelgruppe\n",
    "df_1_art_month=df_new_1.query('Gesamt>0').groupby(\"Monat\")['Weizenbrot','Mischbrot','Vollkornbrot','Spezialbrot','Stangenbrote',\n",
    "                                        'Brötchen','Süsse_Brötchen','Herzhafte_Brötchen','KonditoreiBlech1','KonditoreiBlech2',\n",
    "                                        'Stückgebäck','Blechkuchen',\n",
    "                                        'Weihnachtsartikel'].mean().stack().reset_index()\n",
    "df_1_art_month.rename(columns={0:'Umsatz','level_1':'Artikelgruppe'\n",
    "                          }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df_1_art_month, x=\"Monat\", y='Umsatz', color='Artikelgruppe', barmode='group',\n",
    "             color_discrete_sequence=px.colors.sequential.RdBu, \n",
    "            title=\"Monthly sales on Artikelgruppen for Filiale 1\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filiale 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions FILIALE 2**\n",
    "- `Sales in total have a strong correlation to the weekday. This is  valid for most of the Artikelgruppen..`\n",
    "- `The biggest impact can be seen for Brötchen, Süße Brötchen and Blechkuchen.`\n",
    "- `The highest Salesvolumne per Artikelgruppe was 1798.58€ for Artikelgruppe 11:= Stückgebäck on New Year's Eve\n",
    "2015, everbody buys Berliner for New Year's Eve. This is also the day with the highest Salesvolumne in total.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_new_2.loc[df_new_2['Stückgebäck'].idxmax()][11])\n",
    "print(df_new_2.loc[df_new_2['Stückgebäck'].idxmax()].Datum)\n",
    "print(df_new_2.loc[df_new_2['Gesamt'].idxmax()]['Gesamt'])\n",
    "print(df_new_2.loc[df_new_2['Gesamt'].idxmax()].Datum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales per Warengruppe overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_waren=df_2.groupby('Warengruppe').Umsatz.sum().round(2).reset_index()\n",
    "print(df_2_waren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(df_2_waren, values='Umsatz', names='Warengruppe', color_discrete_sequence=px.colors.sequential.matter)\n",
    "             #color='Warengruppe',\n",
    "             #color_discrete_map={'Brot':'lightcyan',\n",
    "                                # 'Brötchen':'cyan',\n",
    "                                # 'Spezial_Brötchen':'royalblue',\n",
    "                                 #'Konditorei':'royalblue',\n",
    "                                 #'Kuchen':'darkblue'},\n",
    "             \n",
    "fig.update_layout(title_text='Split of the salesvolumne for Filiale 2 / Warengruppenlevel', title_x=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales on Weekdays/Weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis for Warengruppen\n",
    "df_2_wg=df_new_wg2.groupby(\"Wochenende\")['Brot','Brötchen','Konditorei','Kuchen',\n",
    "                                         'Spezial_Brötchen','Weihnachtsartikel'].mean().stack().reset_index()\n",
    "df_2_wg.rename(columns={0:'Umsatz'\n",
    "                          }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df_2_wg, x=\"Warengruppe\", y='Umsatz', color='Wochenende',barmode='group',\n",
    "             color_discrete_sequence=px.colors.sequential.matter, title=\"Weekend sales compared to weekday sales for Filiale 2\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis for Artikelgruppen\n",
    "df_2_art=df_new_2.groupby(\"Wochenende\")['Weizenbrot','Mischbrot','Vollkornbrot','Spezialbrot','Stangenbrote',\n",
    "                                        'Brötchen','Süsse_Brötchen','Herzhafte_Brötchen','KonditoreiBlech1','KonditoreiBlech2',\n",
    "                                        'Stückgebäck','Blechkuchen',\n",
    "                                        'Weihnachtsartikel'].mean().stack().reset_index()\n",
    "df_2_art.rename(columns={0:'Umsatz','level_1':'Artikelgruppe'\n",
    "                          }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df_2_art, x=\"Artikelgruppe\", y='Umsatz', color='Wochenende',barmode='group',\n",
    "             color_discrete_sequence=px.colors.sequential.matter, title=\"Weekend sales compared to weekday sales for Filiale 2\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales on Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis for Warengruppen\n",
    "df_2_wg2=df_new_wg2.groupby(\"Monat\")['Brot','Brötchen','Konditorei','Kuchen',\n",
    "                                         'Spezial_Brötchen','Weihnachtsartikel'].mean().stack().reset_index()\n",
    "df_2_wg2.rename(columns={0:'Umsatz'\n",
    "                          }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df_2_wg2, x=\"Monat\", y='Umsatz', color='Warengruppe',barmode='group',\n",
    "             color_discrete_sequence=px.colors.sequential.matter, title=\"average sales compared on month for Filiale 2\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis for Artikelgruppen\n",
    "df_2_art2=df_new_2.groupby(\"Wochentag\")['Weizenbrot','Mischbrot','Vollkornbrot','Spezialbrot','Stangenbrote',\n",
    "                                        'Brötchen','Süsse_Brötchen','Herzhafte_Brötchen','KonditoreiBlech1','KonditoreiBlech2',\n",
    "                                        'Stückgebäck','Blechkuchen',\n",
    "                                        'Weihnachtsartikel'].mean().stack().reset_index()\n",
    "df_2_art2.rename(columns={0:'Umsatz','level_1':'Artikelgruppe'\n",
    "                          }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df_2_art2, x=\"Wochentag\", y='Umsatz', color='Artikelgruppe',barmode='group',\n",
    "             color_discrete_sequence=px.colors.sequential.matter,\n",
    "              title=\"Weekday sales on Artikelgruppen for Filiale 2\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filiale 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions FILIALE 3**\n",
    "- `Sales in total have a strong correlation to the weekday. This is  valid for most of the Artikelgruppen..`\n",
    "- `The biggest impact can be seen for Brötchen, Süße Brötchen and Blechkuchen.`\n",
    "- `The highest Salesvolumne per Artikelgruppe was 3154.15€ for Artikelgruppe 11:= Stückgebäck on New Year's Eve\n",
    "2017, everbody buys Berliner for New Year's Eve. This is also the day with the highest Salesvolumne in total.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_new_3.loc[df_new_3['Stückgebäck'].idxmax()]['Stückgebäck'])\n",
    "print(df_new_3.loc[df_new_3['Stückgebäck'].idxmax()].Datum)\n",
    "print(df_new_3.loc[df_new_3['Gesamt'].idxmax()]['Gesamt'])\n",
    "print(df_new_3.loc[df_new_3['Gesamt'].idxmax()].Datum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales per Warengruppe overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3_waren=df_3.groupby('Warengruppe').Umsatz.sum().round(2).reset_index()\n",
    "print(df_3_waren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(df_3_waren, values='Umsatz', names='Warengruppe', color_discrete_sequence=px.colors.diverging.balance)\n",
    "             #color='Warengruppe',\n",
    "             #color_discrete_map={'Brot':'lightcyan',\n",
    "                                # 'Brötchen':'cyan',\n",
    "                                # 'Spezial_Brötchen':'royalblue',\n",
    "                                 #'Konditorei':'royalblue',\n",
    "                                 #'Kuchen':'darkblue'},\n",
    "             #title='Split of the salesvolumne for Filiale 3 / Warengruppenlevel')\n",
    "fig.update_layout(title_text='Split of the salesvolumne for Filiale 3 / Warengruppenlevel', title_x=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales on Weekdays/Weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis for Warengruppen\n",
    "df_3_wg=df_new_wg3.groupby(\"Wochenende\")['Brot','Brötchen','Konditorei','Kuchen',\n",
    "                                         'Spezial_Brötchen','Weihnachtsartikel'].mean().stack().reset_index()\n",
    "df_3_wg.rename(columns={0:'Umsatz'\n",
    "                          }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df_3_wg, x=\"Warengruppe\", y='Umsatz', color='Wochenende',barmode='group',\n",
    "             color_discrete_sequence=px.colors.diverging.balance, title=\"Weekend sales compared to weekday sales for Filiale 3\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis for Artikelgruppen\n",
    "df_3_art=df_new_3.groupby(\"Wochenende\")['Weizenbrot','Mischbrot','Vollkornbrot','Spezialbrot','Stangenbrote',\n",
    "                                        'Brötchen','Süsse_Brötchen','Herzhafte_Brötchen','KonditoreiBlech1','KonditoreiBlech2',\n",
    "                                        'Stückgebäck','Blechkuchen',\n",
    "                                        'Weihnachtsartikel'].mean().stack().reset_index()\n",
    "df_3_art.rename(columns={0:'Umsatz','level_1':'Artikelgruppe'\n",
    "                          }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df_3_art, x=\"Artikelgruppe\", y='Umsatz', color='Wochenende',barmode='group',\n",
    "             color_discrete_sequence=px.colors.diverging.balance, title=\"Weekend sales compared to weekday sales for Filiale 3\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sales in dependency of Weekdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis for Artikelgruppen\n",
    "df_3_art2=df_new_3.groupby(\"Wochentag\")['Weizenbrot','Mischbrot','Vollkornbrot','Spezialbrot','Stangenbrote',\n",
    "                                        'Brötchen','Süsse_Brötchen','Herzhafte_Brötchen','KonditoreiBlech1','KonditoreiBlech2',\n",
    "                                        'Stückgebäck','Blechkuchen',\n",
    "                                        'Weihnachtsartikel'].mean().stack().reset_index()\n",
    "df_3_art2.rename(columns={0:'Umsatz','level_1':'Artikelgruppe'\n",
    "                          }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df_3_art2, x=\"Wochentag\", y='Umsatz', color='Artikelgruppe',barmode='group',\n",
    "             color_discrete_sequence=px.colors.diverging.balance\n",
    "             ,\n",
    "              title=\"Weekday sales on Artikelgruppen for Filiale 3\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales on Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis for Warengruppen\n",
    "df_3_wg2=df_new_wg3.groupby(\"Monat\")['Brot','Brötchen','Konditorei','Kuchen',\n",
    "                                         'Spezial_Brötchen','Weihnachtsartikel'].mean().stack().reset_index()\n",
    "df_3_wg2.rename(columns={0:'Umsatz'\n",
    "                          }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = px.bar(df_3_wg2, x=\"Monat\", y='Umsatz', color='Warengruppe',barmode='group',\n",
    "#             color_discrete_sequence=px.colors.diverging.balance, title=\"average sales compared on month for Filiale 3\")\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis for Artikelgruppen\n",
    "\n",
    "df_3_art_month=df_new_3.groupby(\"Monat\")['Weizenbrot','Mischbrot','Vollkornbrot','Spezialbrot','Stangenbrote',\n",
    "                                        'Brötchen','Süsse_Brötchen','Herzhafte_Brötchen','KonditoreiBlech1','KonditoreiBlech2',\n",
    "                                        'Stückgebäck','Blechkuchen',\n",
    "                                        'Weihnachtsartikel'].mean().stack().reset_index()\n",
    "df_3_art_month.rename(columns={0:'Umsatz','level_1':'Artikelgruppe'\n",
    "                          }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df_3_art_month, x=\"Monat\", y='Umsatz', color='Artikelgruppe',barmode='group',color_discrete_sequence=px.colors.diverging.balance,             \n",
    "             title=\"Monthly sales on Artikelgruppen for Filiale 3\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Coronatrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a Gesamt column to all the new dataframes which contains the total sales\n",
    "liste=[df_new_waren]\n",
    "\n",
    "for i in liste:\n",
    "    i['Gesamt']=i['Brot']+i['Brötchen']+i['Konditorei']+i['Spezial_Brötchen']+i['Weihnachtsartikel']\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_waren.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corona=df_new_waren.query('Datum>\"2020-01-01\" and Datum <\"2020-06-01\"')\n",
    "df_2019=df_new_waren.query('Jahr==2019 and Datum <\"2019-06-01\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corona['Woche']=df_corona['Datum'].dt.week\n",
    "df_corona['Tag']=df_corona['Datum'].dt.dayofyear\n",
    "df_2019['Woche']=df_2019['Datum'].dt.week\n",
    "df_2019['Tag']=df_2019['Datum'].dt.dayofyear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corona.Datum.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis on Salesvolumne in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019_ges=df_2019.groupby([\"Woche\",\"Filiale\"])['Gesamt'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corona_ges=df_corona.groupby([\"Woche\",\"Filiale\"])['Gesamt'].mean().reset_index()\n",
    "df_corona_ges.rename(columns={'Gesamt':'Gesamt_2020', 'Woche':'Woche'\n",
    "                          }, \n",
    "                 inplace=True)\n",
    "#df_corona_ges_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gesamt=df_corona_ges.merge(df_2019_ges)\n",
    "df_gesamt[\"Diff\"]=(df_gesamt['Gesamt_2020']-df_gesamt['Gesamt'])/df_gesamt['Gesamt']*100\n",
    "df_gesamt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corona_ges['Jahr']='2020'\n",
    "df_2019_ges['Jahr']='2019'\n",
    "df_gesamt_jahr=pd.concat([df_corona_ges,df_2019_ges])\n",
    "df_gesamt_jahr['Gesamt']=df_gesamt_jahr['Gesamt'].apply(lambda v:0 if np.isnan(v) == True else v)\n",
    "df_gesamt_jahr['Gesamt_2020']=df_gesamt_jahr['Gesamt_2020'].apply(lambda v:0 if np.isnan(v) == True else v)\n",
    "df_gesamt_jahr['Summe']=df_gesamt_jahr['Gesamt']+df_gesamt_jahr['Gesamt_2020']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='Woche',y='Summe',hue='Jahr',data=df_gesamt_jahr,estimator='sum')\n",
    "plt.title = 'Impact of Corona to the average Salesvolumne compared to 2019'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = px.line(df_gesamt, x=\"Woche\",y=\"Diff\",\n",
    "#              labels={\n",
    "#                     \"Woche\": \"Week of the year\",\n",
    "#                     \"Diff\": \"Difference in %\"\n",
    "#                 },color_discrete_sequence=px.colors.sequential.RdBu,\n",
    "#             title=\"Change in Salesvolumne in % due to corona\")\n",
    "#\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = px.bar(df_gesamt_jahr, x=df_gesamt_jahr.Woche, y=\"Summe\",color='Jahr',barmode='group',\n",
    "#             title=\"Sales in 2020 compared to those in 2019 on weekbase\")\n",
    "\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis for the single Filialen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filiale 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corona_1ges=df_gesamt_jahr.query('Filiale==1')\n",
    "df_corona_1=df_gesamt.query('Filiale==1')\n",
    "df_corona_1[\"Diff\"]=(df_corona_1['Gesamt_2020']-df_corona_1['Gesamt'])/df_corona_1['Gesamt']*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df_corona_1ges, x=\"Woche\", y=\"Summe\",color='Jahr',barmode='group',color_discrete_sequence=px.colors.sequential.RdBu,\n",
    "             title=\"Sales in 2020 compared to those in 2019 on weekbase for Filiale 1\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_corona_1, x=\"Woche\", y=\"Diff\",\n",
    "              labels={\n",
    "                     \"Woche\": \"Week of the year\",\n",
    "                     \"Diff\": \"Difference in %\"\n",
    "                 },color_discrete_sequence=px.colors.sequential.RdBu,\n",
    "             title=\"Change in Salesvolumne in % for Filiale 1\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filiale 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corona_2ges=df_gesamt_jahr.query('Filiale==2')\n",
    "df_corona_2=df_gesamt.query('Filiale==2')\n",
    "df_corona_2[\"Diff\"]=(df_corona_2['Gesamt_2020']-df_corona_2['Gesamt'])/df_corona_2['Gesamt']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df_corona_2ges, x=\"Woche\", y=\"Summe\",color='Jahr',barmode='group',color_discrete_sequence=px.colors.sequential.matter,\n",
    "             title=\"Sales in 2020 compared to those in 2019 on weekbase for Filiale 2\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_corona_2, x=\"Woche\", y=\"Diff\",\n",
    "              labels={\n",
    "                     \"Woche\": \"Week of the year\",\n",
    "                     \"Diff\": \"Difference in %\"\n",
    "                 },color_discrete_sequence=px.colors.sequential.RdBu,\n",
    "             title=\"Change in Salesvolumne in % for Filiale 2\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filiale 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corona_3ges=df_gesamt_jahr.query('Filiale==3')\n",
    "df_corona_3=df_gesamt.query('Filiale==3')\n",
    "df_corona_3[\"Diff\"]=(df_corona_3['Gesamt_2020']-df_corona_3['Gesamt'])/df_corona_3['Gesamt']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df_corona_3ges, x=\"Woche\", y=\"Summe\",color='Jahr',barmode='group',color_discrete_sequence=px.colors.diverging.balance,\n",
    "             title=\"Sales in 2020 compared to those in 2019 on weekbase for Filiale 3\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_corona_3, x=\"Woche\", y=\"Diff\",\n",
    "              labels={\n",
    "                     \"Woche\": \"Week of the year\",\n",
    "                     \"Diff\": \"Difference in %\"\n",
    "                 },color_discrete_sequence=px.colors.sequential.RdBu,\n",
    "             title=\"Change in Salesvolumne in % for Filiale 3\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis on Warengruppen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019_wg=df_2019.groupby(\"Woche\")['Brot','Brötchen','Konditorei','Kuchen',\n",
    "                                         'Spezial_Brötchen','Weihnachtsartikel'].sum().stack().reset_index()\n",
    "df_2019_wg.rename(columns={0:'Umsatz'\n",
    "                          }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corona_wg=df_corona.groupby(\"Woche\")['Brot','Brötchen','Konditorei','Kuchen',\n",
    "                                         'Spezial_Brötchen','Weihnachtsartikel'].sum().stack().reset_index()\n",
    "df_corona_wg.rename(columns={0:'Umsatz_2020'\n",
    "                          }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gesamt_wg=df_2019_wg.merge(df_corona_wg)\n",
    "df_gesamt_wg[\"Diff\"]=(df_gesamt_wg['Umsatz_2020']-df_gesamt_wg['Umsatz'])/df_gesamt_wg['Umsatz']*100\n",
    "df_gesamt_wg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='Woche',y='Diff',hue='Warengruppe',data=df_gesamt_wg).set_title('Change in % due to Corona on Warengruppen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filiale 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Explore Coronatrend\n",
    "df_corona_wg_1=df_corona.query('Filiale==1')\n",
    "df_2019_wg_1=df_2019.query('Filiale==1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corona_wg_1=df_corona_wg_1.groupby(\"Woche\")['Brot','Brötchen','Konditorei','Kuchen',\n",
    "                                         'Spezial_Brötchen','Weihnachtsartikel'].sum().stack().reset_index()\n",
    "df_corona_wg_1.rename(columns={0:'Umsatz_2020'\n",
    "                          }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019_wg_1=df_2019_wg_1.groupby(\"Woche\")['Brot','Brötchen','Konditorei','Kuchen',\n",
    "                                         'Spezial_Brötchen','Weihnachtsartikel'].sum().stack().reset_index()\n",
    "df_2019_wg_1.rename(columns={0:'Umsatz'\n",
    "                          }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gesamt_wg_1=df_2019_wg_1.merge(df_corona_wg_1)\n",
    "df_gesamt_wg_1[\"Diff\"]=(df_gesamt_wg_1['Umsatz_2020']-df_gesamt_wg_1['Umsatz'])/df_gesamt_wg_1['Umsatz']*100\n",
    "df_gesamt_wg_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='Woche',y='Diff',hue='Warengruppe',data=df_gesamt_wg_1).set_title(\"Change in % due to Corona on Warengruppen for Filiale 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filiale 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Explore Coronatrend for Filiale 2\n",
    "df_corona_wg_2=df_corona.query('Filiale==2')\n",
    "df_2019_wg_2=df_2019.query('Filiale==2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corona_wg_2=df_corona_wg_2.groupby(\"Woche\")['Brot','Brötchen','Konditorei','Kuchen',\n",
    "                                         'Spezial_Brötchen','Weihnachtsartikel'].mean().stack().reset_index()\n",
    "df_corona_wg_2.rename(columns={0:'Umsatz_2020'\n",
    "                          }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019_wg_2=df_2019_wg_2.groupby(\"Woche\")['Brot','Brötchen','Konditorei','Kuchen',\n",
    "                                         'Spezial_Brötchen','Weihnachtsartikel'].mean().stack().reset_index()\n",
    "df_2019_wg_2.rename(columns={0:'Umsatz'\n",
    "                          }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gesamt_wg_2=df_2019_wg_2.merge(df_corona_wg_2)\n",
    "df_gesamt_wg_2[\"Diff\"]=(df_gesamt_wg_2['Umsatz_2020']-df_gesamt_wg_2['Umsatz'])/df_gesamt_wg_2['Umsatz']*100\n",
    "df_gesamt_wg_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='Woche',y='Diff',hue='Warengruppe',data=df_gesamt_wg_2).set_title('Change in % due to Corona on Warengruppen for Filiale 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filiale 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Explore Coronatrend\n",
    "df_corona_wg_3=df_corona.query('Filiale==3')\n",
    "df_2019_wg_3=df_2019.query('Filiale==3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corona_wg_3=df_corona_wg_3.groupby(\"Woche\")['Brot','Brötchen','Konditorei','Kuchen',\n",
    "                                         'Spezial_Brötchen','Weihnachtsartikel'].sum().stack().reset_index()\n",
    "df_corona_wg_3.rename(columns={0:'Umsatz_2020'\n",
    "                          }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019_wg_3=df_2019_wg_3.groupby(\"Woche\")['Brot','Brötchen','Konditorei','Kuchen',\n",
    "                                         'Spezial_Brötchen','Weihnachtsartikel'].mean().stack().reset_index()\n",
    "df_2019_wg_3.rename(columns={0:'Umsatz'\n",
    "                          }, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gesamt_wg_3=df_2019_wg_3.merge(df_corona_wg_3)\n",
    "df_gesamt_wg_3[\"Diff\"]=(df_gesamt_wg_3['Umsatz_2020']-df_gesamt_wg_3['Umsatz'])/df_gesamt_wg_3['Umsatz']*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='Woche',y='Diff',hue='Warengruppe',data=df_gesamt_wg_3).set_title('Change in % due to Corona on Warengruppen for Filiale 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spezial Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions Bread**\n",
    "- `There are in total 166 negative sales values. Affected are Artikelgruppe 5, 2 and 10.`\n",
    "- `Maybe the negative values arise from unsold articles which can not be further processed to basketmehl.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming Columnlabels\n",
    "df['Artikelgruppe']=df['Artikelgruppe'].apply(lambda x: 'Weizenbrot' if x==1 else \"Mischbrot\" if x==2 else \n",
    "                    \"Vollkornbrot\" if x==3 else \"Spezialbrot\" if x==4 else \"Stangenbrote\" if x==5 else \"Brötchen\"\n",
    "                                                  if x==6 else \"Süsse_Brötchen\" if x==7 else\n",
    "                                              \"Herzhafte_Brötchen\" if x==8 else \"KonditoreiBlech1\" if x==9\n",
    "                                                  else \"KonditoreiBlech2\" if x==10 else \"Stückgebäck\" \n",
    "                                              if x==11 else\n",
    "                                              \"Blechkuchen\" if x==12 else \"Weihnachtsartikel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brot=df.query('Warengruppe ==\"Brot\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(df_brot, values='Umsatz', names='Artikelgruppe',\n",
    "             color='Artikelgruppe',\n",
    "             color_discrete_map={'Vollkornbrot':'green',\n",
    "                                'Spezialbrot':'red',\n",
    "                                'Weizenbrot':'royalblue',\n",
    "                                 'Mischbrot':'orange',\n",
    "                                 'Stangenbrote':'purple'})\n",
    "fig.update_layout(title_text='Articlegroup Breakdown Brot sales', title_x=0.45)             \n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='Jahr',y='Umsatz',hue='Artikelgruppe',data=df_brot,estimator='mean').set_title('Revenue per articlegroup for Brot and year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brot.groupby(['Jahr','Artikelgruppe']).Umsatz.mean().unstack().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stangenbrote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stangenbrote=df.query('Artikelgruppe ==\"Stangenbrote\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='Jahr',y='Umsatz',hue='Artikelgruppe',data=df_stangenbrote,estimator='mean').set_title('Revenue per articlegroup for Stangenbrote per year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_stangenbrote.loc[df_stangenbrote['Umsatz'].idxmax()]['Umsatz'])\n",
    "print(df_stangenbrote.loc[df_stangenbrote['Umsatz'].idxmax()].Datum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brötchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brötchen=df.query('Warengruppe in (\"Brötchen\",\"Spezial_Brötchen\")')\n",
    "df_brötchen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='Jahr',y='Umsatz',hue='Artikelgruppe',data=df_brötchen,estimator='mean').set_title('Revenue per all Brötchen per year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='Monat',y='Umsatz',hue='Artikelgruppe',data= df_brötchen,estimator='mean').set_title('Revenue per articlegroup for all Brötchen per month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse the \"Brötchenhype\" during the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_art_month_spez=df_new_2.groupby(\"Monat\")['Brötchen'].mean().reset_index()\n",
    "mean=df_2_art_month_spez.mean().Brötchen\n",
    "df_2_art_month_spez['Abweichung vom Mittelwert in %']=((df_2_art_month_spez['Brötchen']-mean)/mean)*100\n",
    "summe=sum(df_2_art_month_spez['Brötchen'])\n",
    "df_2_art_month_spez['Anteil des Jahresumsatzes in %']=(df_2_art_month_spez['Brötchen']/summe)*100\n",
    "\n",
    "#df_2_art_month_spez['Abweichung zum Vormonat'] = [df_2_art_month_spez[i] for i \n",
    "#                                                  in df_2_art_month_spez['Monat']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_art_month_spez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kuchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kuchen=df.query('Warengruppe in (\"Kuchen\",\"Konditorei\")')\n",
    "df_kuchen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='Jahr',y='Umsatz',hue='Artikelgruppe',data=df_kuchen,estimator='mean').set_title('Revenue per articlegroup for cakes and cupcakes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kuchen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kond2=df_kuchen.query('Artikelgruppe==\"KonditoreiBlech2\" and Jahr>=2019')\n",
    "df_kond2_group=df_kond2.groupby(['Filiale','Jahr','Monat'])\n",
    "df_kond2_group_umsatz=df_kond2_group['Umsatz'].agg(['mean','max','count'])\n",
    "df_kond2_group_umsatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weihnachtsartikel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weihnachtsartikel=df.query('Warengruppe in (\"Weihnachtsartikel\")')\n",
    "df_weihnachtsartikel=(df_weihnachtsartikel.groupby(['Filiale','Jahr','Monat']).Umsatz.agg(['sum','mean','median','max','count']))\n",
    "#df_weihnachtsartikel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sommertrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sommer_ges=df\n",
    "df_sommer_ges['Tag']=df_sommer_ges['Datum'].dt.dayofyear\n",
    "df_sommer=df.query('Monat in (5,6,7,8,9)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sommer_summe=df_sommer.groupby(['Filiale','Jahr','Monat']).Umsatz.sum().reset_index()\n",
    "df_sommer_summe=df_sommer_summe.pivot_table(index=['Jahr','Monat'],columns='Filiale',values='Umsatz',margins=True)\n",
    "#df_sommer_summe.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='Monat',y='Umsatz',hue='Jahr',data=df_sommer,estimator='mean').set_title('Average Revenue in total for the summermonths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sommer_2019=df.query('Jahr <2020')\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='Monat',y='Umsatz',hue='Jahr',data=df_sommer_2019,estimator='sum').set_title('Revenue in total for the summermonths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sommer_2019=df_sommer.query('Jahr <2020')\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='Monat',y='Umsatz',hue='Jahr',data=df_sommer_2019,estimator='sum').set_title('Revenue in total for the summermonths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sommer_2015=df_sommer.query('Jahr==2015')\n",
    "print(df_stangenbrote.loc[df_stangenbrote['Umsatz'].idxmax()]['Umsatz'])\n",
    "print(df_stangenbrote.loc[df_stangenbrote['Umsatz'].idxmax()].Datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sommer_max=df_new.query('Monat in (5,6,7,8,9)').groupby('Datum')['Gesamt'].sum().reset_index()\n",
    "sommer_max['Jahr']=sommer_max['Datum'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valuation of the day with the hightest sales revenue during sommer 2015\n",
    "sommer_max_2015=sommer_max.query('Jahr==2015')\n",
    "print(sommer_max_2015.loc[sommer_max_2015['Gesamt'].idxmax()]['Gesamt'])\n",
    "print(sommer_max_2015.loc[sommer_max_2015['Gesamt'].idxmax()].Datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valuation of the day with the hightest sales revenue during sommer 2016\n",
    "sommer_max_2016=sommer_max.query('Jahr==2016')\n",
    "print(sommer_max_2016.loc[sommer_max_2016['Gesamt'].idxmax()]['Gesamt'])\n",
    "print(sommer_max_2016.loc[sommer_max_2016['Gesamt'].idxmax()]['Datum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valuation of the day with the hightest sales revenue during sommer 2017\n",
    "sommer_max_2017=sommer_max.query('Jahr==2017')\n",
    "print(sommer_max_2017.loc[sommer_max_2017['Gesamt'].idxmax()]['Gesamt'])\n",
    "print(sommer_max_2017.loc[sommer_max_2017['Gesamt'].idxmax()].Datum)\n",
    "print(sommer_max_2017.loc[sommer_max_2017['Gesamt'].idxmax()].Datum.weekday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valuation of the day with the hightest sales revenue during sommer 2018\n",
    "sommer_max_2018=sommer_max.query('Jahr==2018')\n",
    "print(sommer_max_2018.loc[sommer_max_2018['Gesamt'].idxmax()]['Gesamt'])\n",
    "print(sommer_max_2018.loc[sommer_max_2018['Gesamt'].idxmax()].Datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valuation of the day with the hightest sales revenue during sommer 2019\n",
    "sommer_max_2019=sommer_max.query('Jahr==2019')\n",
    "print(sommer_max_2019.loc[sommer_max_2019['Gesamt'].idxmax()]['Gesamt'])\n",
    "print(sommer_max_2019.loc[sommer_max_2019['Gesamt'].idxmax()].Datum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA-Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_1['KonditoreiBlech1']=df_new_1['KonditoreiBlech1']+df_new_1['KonditoreiBlech2']\n",
    "df_new_1.rename(columns={'KonditoreiBlech1':'KonditoreiBlech'}, inplace=True)\n",
    "df_new_1.drop('KonditoreiBlech2',axis='columns', inplace=True)\n",
    "\n",
    "df_new_2['KonditoreiBlech1']=df_new_2['KonditoreiBlech1']+df_new_2['KonditoreiBlech2']\n",
    "df_new_2.rename(columns={'KonditoreiBlech1':'KonditoreiBlech'}, inplace=True)\n",
    "df_new_2.drop('KonditoreiBlech2',axis='columns', inplace=True)\n",
    "\n",
    "df_new_3['KonditoreiBlech1']=df_new_3['KonditoreiBlech1']+df_new_3['KonditoreiBlech2']\n",
    "df_new_3.rename(columns={'KonditoreiBlech1':'KonditoreiBlech'}, inplace=True)\n",
    "df_new_3.drop('KonditoreiBlech2',axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_1.to_csv(\"df_new_1.csv\")\n",
    "df_new_2.to_csv(\"df_new_2.csv\")\n",
    "df_new_3.to_csv(\"df_new_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test=pd.read_csv(\"df_new_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basis_1=df_new_1.iloc[:,0:13]\n",
    "df_basis_2=df_new_2.iloc[:,0:13]\n",
    "df_basis_3=df_new_3.iloc[:,0:13]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change of the Wochenende column\n",
    "df_new_2['Wochenende_flag']=df_new_2['Wochenende'].apply(lambda x: 1 if x=='Wochenende' else 0)\n",
    "df_new_2['Wochenende_flag']=pd.to_numeric(df_new_2['Wochenende'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def season_of_date(date):\n",
    "    year = str(date.year)\n",
    "    seasons = {'spring': pd.date_range(start='21/03/'+year, end='20/06/'+year),\n",
    "               'summer': pd.date_range(start='21/06/'+year, end='22/09/'+year),\n",
    "               'autumn': pd.date_range(start='23/09/'+year, end='20/12/'+year)}\n",
    "    if date in seasons['spring']:\n",
    "        return '1'\n",
    "    if date in seasons['summer']:\n",
    "        return '2'\n",
    "    if date in seasons['autumn']:\n",
    "        return '3'\n",
    "    else:\n",
    "        return '4'\n",
    "\n",
    "# Assuming df has a date column of type `datetime`\n",
    "df_new_2['Season'] = df_new_2.Datum.map(season_of_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flag Closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_2['Closed']=df_new_2['Gesamt'].apply(lambda x: 1 if x==0 else 0)\n",
    "df_new_2['Closed']=pd.to_numeric(df_new_2['Closed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Features for Salesvolumne in the past (one and two year ago)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Value of the previous Year\n",
    "df_new_2['Brötchen_364'] = df_new_2.Brötchen.shift(364)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wheather data from dwd/weste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holidays - type and flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holidays_sh(date):\n",
    "   # year = str(date.year)\n",
    "    holidays = {'Weihnachten': pd.date_range(start='20/12/2018', end='06/01/2019'),\n",
    "                #'Weihnachten': pd.date_range(start='20/12/2018', end='06/01/2019'),\n",
    "               'Ostern': pd.date_range(start='04/04/2019', end='22/04/2019'),\n",
    "               'Pfingsten':pd.date_range(start='30/05/2019', end='02/06/2019'),\n",
    "               'Sommer': pd.date_range(start='29/06/2019', end='11/08/2019'),\n",
    "               'Herbst': pd.date_range(start='04/10/2019', end='20/10/2019')}\n",
    "    if date in holidays['Weihnachten']:\n",
    "        return 1\n",
    "    if date in holidays['Ostern']:\n",
    "        return 2\n",
    "    if date in holidays['Pfingsten']:\n",
    "        return 3\n",
    "    if date in holidays['Sommer']:\n",
    "        return 4\n",
    "    if date in holidays['Herbst']:\n",
    "        return 5\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Assuming df has a date column of type `datetime`\n",
    "df_new_2['Holidays_SH'] = df_new_2.Datum.map(holidays_sh)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verkaufsfreie Sonntage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other dates of importance like Kieler Woche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corona dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checks Timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose weekly, monthly and yearly effects as well as trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_1 = df_new_1.set_index('Datum')\n",
    "df_new_2 = df_new_2.set_index('Datum')\n",
    "df_new_3 = df_new_3.set_index('Datum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration for Filiale 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jahr = 2019\n",
    "\n",
    "#for idx,fil in enumerate([df_new_1,df_new_2,df_new_3],1):\n",
    "y = df_new_1[df_new_1.index.year == Jahr].Gesamt\n",
    "rcParams['figure.figsize'] = 18, 8\n",
    "decomposition = sm.tsa.seasonal_decompose(y, model='aditive',period=7)\n",
    "fig = decomposition.plot()\n",
    "       \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration for Filiale 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jahr = 2019\n",
    "#for idx,fil in enumerate([df_new_1,df_new_2,df_new_3],1):\n",
    "y = df_new_2[df_new_2.index.year == Jahr].Gesamt\n",
    "#sum(axis=1)\n",
    "rcParams['figure.figsize'] = 18, 8\n",
    "decomposition = sm.tsa.seasonal_decompose(y, model='aditive',period=7)\n",
    "fig = decomposition.plot()\n",
    "       \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration for Filiale 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jahr = 2019\n",
    "#for idx,fil in enumerate([df_new_1,df_new_2,df_new_3],1):\n",
    "y = df_new_3[df_new_3.index.year == Jahr].Gesamt\n",
    "rcParams['figure.figsize'] = 18, 8\n",
    "decomposition = sm.tsa.seasonal_decompose(y, model='aditive',period=7)\n",
    "fig = decomposition.plot()\n",
    "       \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before Corona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_1_index=df_new_1.set_index('Datum')\n",
    "df_new_2_index=df_new_2.set_index('Datum')\n",
    "df_new_3_index=df_new_3.set_index('Datum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1_gesamt=df_new_1_index.Gesamt[:'15.03.2020']\n",
    "y_2_gesamt=df_new_2_index.Gesamt[:'15.03.2020']\n",
    "y_3_gesamt=df_new_3_index.Gesamt[:'15.03.2020']\n",
    "y_gesamt=df_new_index.Gesamt[:'15.03.2020']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filiale 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**\n",
    "- `From the plot you can see there is a peak in correlation at the lag of 7th day, then again on the 14th day\n",
    "and so on. The series is perfectly autocorrelated with a lag of 1 week.`\n",
    "- `This is valid for all single articlegroups with the exception Weihnachtsartikel. See single plots.`\n",
    "- `For the articlegroups Weihnachtsartikel, Blechkuchen and Stangenbrote you see a  peak in correlation at the lag of 365th day.`\n",
    "- `For  articlegroup Stangenbrote both peaks are quite low compared to those of the other groups.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\n",
    "fig.suptitle('AC and PAC for Filiale 1')\n",
    "sm.graphics.tsa.plot_acf(df_new_1.Gesamt.squeeze(), lags=200, ax=ax1)\n",
    "sm.graphics.tsa.plot_pacf(df_new_1.Gesamt.squeeze(), lags=40, ax=ax2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,4,figsize=(20,15))\n",
    "\n",
    "sm.graphics.tsa.plot_acf(df_basis_1['Blechkuchen'].squeeze(), lags=20, ax=axes[0,0])\n",
    "axes[0, 0].set_title('Blechkuchen')\n",
    "sm.graphics.tsa.plot_acf(df_basis_1['Stückgebäck'].squeeze(), lags=20, ax=axes[0,1])\n",
    "axes[0, 1].set_title('Stückgebäck')\n",
    "sm.graphics.tsa.plot_acf(df_basis_1['KonditoreiBlech'].squeeze(), lags=20, ax=axes[0,2])\n",
    "axes[0, 2].set_title('KonditoreiBlech')\n",
    "sm.graphics.tsa.plot_acf(df_basis_1['Brötchen'].squeeze(), lags=20, ax=axes[0,3])\n",
    "axes[0,3].set_title('Brötchen')\n",
    "sm.graphics.tsa.plot_acf(df_basis_1['Süsse_Brötchen'].squeeze(), lags=20, ax=axes[1,0])\n",
    "axes[1,0].set_title('Süsse_Brötchen')\n",
    "sm.graphics.tsa.plot_acf(df_basis_1['Herzhafte_Brötchen'].squeeze(), lags=20, ax=axes[1,1])\n",
    "axes[1,1].set_title('Herzhafte Brötchen')\n",
    "sm.graphics.tsa.plot_acf(df_basis_1['Mischbrot'].squeeze(), lags=20, ax=axes[1,2])\n",
    "axes[1,2].set_title('Mischbrot')\n",
    "sm.graphics.tsa.plot_acf(df_basis_1['Vollkornbrot'].squeeze(), lags=20, ax=axes[1,3])\n",
    "axes[1,3].set_title('Vollkornbrot')\n",
    "sm.graphics.tsa.plot_acf(df_basis_1['Spezialbrot'].squeeze(), lags=20, ax=axes[2,0])\n",
    "axes[2,0].set_title('Spezialbrot')\n",
    "sm.graphics.tsa.plot_acf(df_basis_1['Stangenbrote'].squeeze(), lags=20, ax=axes[2,1])\n",
    "axes[2,1].set_title('Stangenbrote')\n",
    "sm.graphics.tsa.plot_acf(df_basis_1['Weizenbrot'].squeeze(), lags=20, ax=axes[2,2])\n",
    "axes[2,2].set_title('Weizenbrot')\n",
    "sm.graphics.tsa.plot_acf(df_basis_1['Weihnachtsartikel'].squeeze(), lags=20, ax=axes[2,3])\n",
    "axes[2,3].set_title('Weihnachtsartikel')\n",
    "\n",
    "   \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3,figsize=(20,5))\n",
    "\n",
    "sm.graphics.tsa.plot_acf(df_basis_1['Blechkuchen'].squeeze(), lags=365, ax=axes[0])\n",
    "axes[0].set_title('Blechkuchen')\n",
    "sm.graphics.tsa.plot_acf(df_basis_1['Stangenbrote'].squeeze(), lags=365, ax=axes[1])\n",
    "axes[1].set_title('Stangenbrote')\n",
    "\n",
    "sm.graphics.tsa.plot_acf(df_basis_1['Weihnachtsartikel'].squeeze(), lags=365, ax=axes[2])\n",
    "axes[2].set_title('Weihnachtsartikel')\n",
    "\n",
    "   \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filiale 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**\n",
    "- `From the plot you can see there is a high peak in correlation at the lag of 7th day, then again on the 14th day\n",
    "and so on. The series is perfectly autocorrelated with a lag of 1 week.`\n",
    "- `This is valid for all single articlegroups with the exception Weihnachtsartikel. See single plots.`\n",
    "- `For all articlegroups except Brot(Vollkornbrot, Weizenbrot,..) you see a  peak in correlation at the lag of 365th day.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autocorrelation totalsales 2019 - Filiale 2\n",
    "#from pandas.plotting import autocorrelation_plot\n",
    "#plt.figure(figsize=(15,5))\n",
    "#autocorrelation_plot(y_2_gesamt).set_title(\" Autocorrelation totalsales 2019 - Filiale 2\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(16,5))\n",
    "fig.suptitle('AC and PAC for Filiale 2')\n",
    "sm.graphics.tsa.plot_acf(df_new_2.Gesamt.squeeze(), lags=20, ax=ax1)\n",
    "sm.graphics.tsa.plot_pacf(df_new_2.Gesamt.squeeze(), lags=20, ax=ax2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,4,figsize=(20,15))\n",
    "\n",
    "sm.graphics.tsa.plot_acf(df_basis_2['Blechkuchen'].squeeze(), lags=40, ax=axes[0,0])\n",
    "axes[0, 0].set_title('Blechkuchen')\n",
    "sm.graphics.tsa.plot_acf(df_basis_2['Stückgebäck'].squeeze(), lags=40, ax=axes[0,1])\n",
    "axes[0, 1].set_title('Stückgebäck')\n",
    "sm.graphics.tsa.plot_acf(df_basis_2['KonditoreiBlech'].squeeze(), lags=40, ax=axes[0,2])\n",
    "axes[0, 2].set_title('KonditoreiBlech')\n",
    "sm.graphics.tsa.plot_acf(df_basis_2['Brötchen'].squeeze(), lags=40, ax=axes[0,3])\n",
    "axes[0,3].set_title('Brötchen')\n",
    "sm.graphics.tsa.plot_acf(df_basis_2['Süsse_Brötchen'].squeeze(), lags=40, ax=axes[1,0])\n",
    "axes[1,0].set_title('Süsse_Brötchen')\n",
    "sm.graphics.tsa.plot_acf(df_basis_2['Herzhafte_Brötchen'].squeeze(), lags=40, ax=axes[1,1])\n",
    "axes[1,1].set_title('Herzhafte Brötchen')\n",
    "sm.graphics.tsa.plot_acf(df_basis_2['Mischbrot'].squeeze(), lags=40, ax=axes[1,2])\n",
    "axes[1,2].set_title('Mischbrot')\n",
    "sm.graphics.tsa.plot_acf(df_basis_2['Vollkornbrot'].squeeze(), lags=40, ax=axes[1,3])\n",
    "axes[1,3].set_title('Vollkornbrot')\n",
    "sm.graphics.tsa.plot_acf(df_basis_2['Spezialbrot'].squeeze(), lags=40, ax=axes[2,0])\n",
    "axes[2,0].set_title('Spezialbrot')\n",
    "sm.graphics.tsa.plot_acf(df_basis_2['Stangenbrote'].squeeze(), lags=40, ax=axes[2,1])\n",
    "axes[2,1].set_title('Stangenbrote')\n",
    "sm.graphics.tsa.plot_acf(df_basis_2['Weizenbrot'].squeeze(), lags=40, ax=axes[2,2])\n",
    "axes[2,2].set_title('Weizenbrot')\n",
    "sm.graphics.tsa.plot_acf(df_basis_2['Weihnachtsartikel'].squeeze(), lags=40, ax=axes[2,3])\n",
    "axes[2,3].set_title('Weihnachtsartikel')\n",
    "\n",
    "   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,4,figsize=(20,15))\n",
    "\n",
    "sm.graphics.tsa.plot_acf(df_basis_2['Blechkuchen'].squeeze(), lags=365, ax=axes[0,0])\n",
    "axes[0, 0].set_title('Blechkuchen')\n",
    "sm.graphics.tsa.plot_acf(df_basis_2['Stückgebäck'].squeeze(), lags=365, ax=axes[0,1])\n",
    "axes[0, 1].set_title('Stückgebäck')\n",
    "sm.graphics.tsa.plot_acf(df_basis_2['KonditoreiBlech'].squeeze(), lags=365, ax=axes[0,2])\n",
    "axes[0, 2].set_title('KonditoreiBlech')\n",
    "sm.graphics.tsa.plot_acf(df_basis_2['Brötchen'].squeeze(), lags=365, ax=axes[0,3])\n",
    "axes[0,3].set_title('Brötchen')\n",
    "sm.graphics.tsa.plot_acf(df_basis_2['Süsse_Brötchen'].squeeze(), lags=365, ax=axes[1,0])\n",
    "axes[1,0].set_title('Süsse_Brötchen')\n",
    "sm.graphics.tsa.plot_acf(df_basis_2['Herzhafte_Brötchen'].squeeze(), lags=365, ax=axes[1,1])\n",
    "axes[1,1].set_title('Herzhafte Brötchen')\n",
    "\n",
    "sm.graphics.tsa.plot_acf(df_basis_2['Stangenbrote'].squeeze(), lags=365, ax=axes[1,2])\n",
    "axes[1,2].set_title('Stangenbrote')\n",
    "\n",
    "sm.graphics.tsa.plot_acf(df_basis_2['Weihnachtsartikel'].squeeze(), lags=365, ax=axes[1,3])\n",
    "axes[1,3].set_title('Weihnachtsartikel')\n",
    "\n",
    "   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filiale 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**\n",
    "- `From the plot you can see there is a high peak in correlation at the lag of 7th day, then again on the 14th day\n",
    "and so on. The series is perfectly autocorrelated with a lag of 1 week.`\n",
    "- `This is valid for all single articlegroups with the exception Weihnachtsartikel and Stückgebäck. See single plots.`\n",
    "- `For the articlegroups Weihnachtsartikel and Stückgebäck you see a  peak in correlation at the lag of 365th day. For  articlegroups Stangenbrote und Spezialbrot you see a small peak here.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\n",
    "fig.suptitle('AC and PAC for Filiale 3')\n",
    "sm.graphics.tsa.plot_acf(df_new_3.Gesamt.squeeze(), lags=20, ax=ax1)\n",
    "sm.graphics.tsa.plot_pacf(df_new_3.Gesamt.squeeze(), lags=20, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,4,figsize=(20,15))\n",
    "\n",
    "sm.graphics.tsa.plot_acf(df_basis_3['Blechkuchen'].squeeze(), lags=20, ax=axes[0,0])\n",
    "axes[0, 0].set_title('Blechkuchen')\n",
    "sm.graphics.tsa.plot_acf(df_basis_3['Stückgebäck'].squeeze(), lags=20, ax=axes[0,1])\n",
    "axes[0, 1].set_title('Stückgebäck')\n",
    "sm.graphics.tsa.plot_acf(df_basis_3['KonditoreiBlech'].squeeze(), lags=20, ax=axes[0,2])\n",
    "axes[0, 2].set_title('KonditoreiBlech')\n",
    "sm.graphics.tsa.plot_acf(df_basis_3['Brötchen'].squeeze(), lags=20, ax=axes[0,3])\n",
    "axes[0,3].set_title('Brötchen')\n",
    "sm.graphics.tsa.plot_acf(df_basis_3['Süsse_Brötchen'].squeeze(), lags=20, ax=axes[1,0])\n",
    "axes[1,0].set_title('Süsse_Brötchen')\n",
    "sm.graphics.tsa.plot_acf(df_basis_3['Herzhafte_Brötchen'].squeeze(), lags=20, ax=axes[1,1])\n",
    "axes[1,1].set_title('Herzhafte Brötchen')\n",
    "sm.graphics.tsa.plot_acf(df_basis_3['Mischbrot'].squeeze(), lags=20, ax=axes[1,2])\n",
    "axes[1,2].set_title('Mischbrot')\n",
    "sm.graphics.tsa.plot_acf(df_basis_3['Vollkornbrot'].squeeze(), lags=20, ax=axes[1,3])\n",
    "axes[1,3].set_title('Vollkornbrot')\n",
    "sm.graphics.tsa.plot_acf(df_basis_3['Spezialbrot'].squeeze(), lags=20, ax=axes[2,0])\n",
    "axes[2,0].set_title('Spezialbrot')\n",
    "sm.graphics.tsa.plot_acf(df_basis_3['Stangenbrote'].squeeze(), lags=20, ax=axes[2,1])\n",
    "axes[2,1].set_title('Stangenbrote')\n",
    "sm.graphics.tsa.plot_acf(df_basis_3['Weizenbrot'].squeeze(), lags=20, ax=axes[2,2])\n",
    "axes[2,2].set_title('Weizenbrot')\n",
    "sm.graphics.tsa.plot_acf(df_basis_3['Weihnachtsartikel'].squeeze(), lags=20, ax=axes[2,3])\n",
    "axes[2,3].set_title('Weihnachtsartikel')\n",
    "\n",
    "   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,4,figsize=(20,5))\n",
    "\n",
    "\n",
    "sm.graphics.tsa.plot_acf(df_basis_3['Stückgebäck'].squeeze(), lags=365, ax=axes[0])\n",
    "axes[0].set_title('Stückgebäck')\n",
    "\n",
    "sm.graphics.tsa.plot_acf(df_basis_3['Spezialbrot'].squeeze(), lags=365, ax=axes[1])\n",
    "axes[1].set_title('Spezialbrot')\n",
    "sm.graphics.tsa.plot_acf(df_basis_3['Stangenbrote'].squeeze(), lags=365, ax=axes[2])\n",
    "axes[2].set_title('Stangenbrote')\n",
    "\n",
    "sm.graphics.tsa.plot_acf(df_basis_3['Weihnachtsartikel'].squeeze(), lags=365, ax=axes[3])\n",
    "axes[3].set_title('Weihnachtsartikel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**\n",
    "- `The Sales cannot be predicted under the changing corona circumstances.So I decided to not predict sales with date after 15.03.2020.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_corona=df_new_index.Gesamt['01.03.2020':]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autocorrelation totalsales 2020\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "plt.figure(figsize=(15,5))\n",
    "autocorrelation_plot(df_new_index.Gesamt['15.03.2020':]).set_title(\" Autocorrelation totalsales until 2020 - Total\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\n",
    "fig.suptitle('AC and PAC during corona')\n",
    "sm.graphics.tsa.plot_acf(df_new_index.Gesamt['15.03.2020':].squeeze(), lags=40, ax=ax1)\n",
    "sm.graphics.tsa.plot_pacf(df_new_index.Gesamt['15.03.2020':].squeeze(), lags=40, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basis_1=df_basis_1.set_index('Datum')\n",
    "df_basis_1_freq = df_basis_1.asfreq('D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basis_2=df_basis_2.set_index('Datum')\n",
    "df_basis_2_freq = df_basis_2.asfreq('D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basis_3=df_basis_3.set_index('Datum')\n",
    "df_basis_3_freq = df_basis_3.asfreq('D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filiale 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented Dickey-Fuller Test (ADF Test)/unit root test\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "def adf_test(ts, signif=0.01):\n",
    "    dftest = adfuller(ts, autolag='t-stat')\n",
    "    adf = pd.Series(dftest[0:4], index=['Test Statistic','p-value','# Lags','# Observations'])\n",
    "    for key,value in dftest[4].items():\n",
    "       adf['Critical Value (%s)'%key] = value\n",
    "    \n",
    "    p = adf['p-value']\n",
    "    if p <= signif:\n",
    "        pass\n",
    "        #print(f\" Series is Stationary\")\n",
    "    else:\n",
    "        print(f\"Ergebnis für Timeseries {name}:\")\n",
    "        print (adf)\n",
    "        print(f\" Series is Non-Stationary\")\n",
    "#apply adf test on the series\n",
    "\n",
    "for name in df_basis_1.columns:\n",
    "    adf_test(df_basis_1[name])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filiale 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented Dickey-Fuller Test (ADF Test)/unit root test\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "def adf_test(ts, signif=0.01):\n",
    "    dftest = adfuller(ts, autolag='t-stat')\n",
    "    adf = pd.Series(dftest[0:4], index=['Test Statistic','p-value','# Lags','# Observations'])\n",
    "    for key,value in dftest[4].items():\n",
    "       adf['Critical Value (%s)'%key] = value\n",
    "    \n",
    "    \n",
    "    p = adf['p-value']\n",
    "    if p <= signif:\n",
    "        pass\n",
    "        #print(f\" Series is Stationary\")\n",
    "    else:\n",
    "        print(f\"Ergebnis für Timeseries {name}:\")\n",
    "        print (adf)\n",
    "        print(f\" Series is Non-Stationary\")\n",
    "#apply adf test on the series\n",
    "\n",
    "for name in df_basis_2.columns:\n",
    "    adf_test(df_basis_2[name])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filiale 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented Dickey-Fuller Test (ADF Test)/unit root test\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "def adf_test(ts, signif=0.01):\n",
    "    dftest = adfuller(ts, autolag='AIC')\n",
    "    adf = pd.Series(dftest[0:4], index=['Test Statistic','p-value','# Lags','# Observations'])\n",
    "    for key,value in dftest[4].items():\n",
    "       adf['Critical Value (%s)'%key] = value\n",
    "     \n",
    "    p = adf['p-value']\n",
    "    if p <= signif:\n",
    "        pass\n",
    "        #print(f\" Series is Stationary\")\n",
    "    else:\n",
    "        print(f\"Ergebnis für Timeseries {name}:\")\n",
    "        print (adf)\n",
    "        print(f\" Series is Non-Stationary\")\n",
    "#apply adf test on the series\n",
    "\n",
    "for name in df_basis_3.columns:\n",
    "    adf_test(df_basis_3[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Causality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**\n",
    "- `Looking at the p-Values we can assume that almost all variables are not interchangeably each user.`\n",
    "- `A exception is the articlegroup Blechkuchen. Here are assocations to KonditoreiBlech, Süsse_Brötchen and Stangenbrote.`\n",
    "- `Overall this justifies an univariate approach for prediction.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlag=12\n",
    "test = 'ssr-chi2test'\n",
    "\n",
    "def grangers_causality_matrix(X_train, variables,Filiale, test = 'ssr_chi2test', verbose=False):\n",
    "   dataset = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "   for c in dataset.columns:\n",
    "    for r in dataset.index:\n",
    "        test_result = grangercausalitytests(X_train[[r,c]], maxlag=maxlag, verbose=False)\n",
    "        p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n",
    "        if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n",
    "        min_p_value = np.min(p_values)\n",
    "        dataset.loc[r,c] = min_p_value\n",
    "        \n",
    "    dataset.columns = [var + '_x_'+ Filiale for var in variables]\n",
    "    dataset.index = [var + '_y' for var in variables]\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1=grangers_causality_matrix(df_basis_1, df_basis_1.columns,Filiale='Filiale_1')\n",
    "result_2=grangers_causality_matrix(df_basis_2, df_basis_2.columns,Filiale='Filiale_2')\n",
    "result_3=grangers_causality_matrix(df_basis_3, df_basis_3.columns,Filiale='Filiale_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([result_1.iloc[:,0:1],result_2.iloc[:,0:1],result_3.iloc[:,0:1]], axis = 1, sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Conclusions**\n",
    "- `I choose MAE and MAPE as Performance Measures for my project.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I would analyse the results from the different models via the two different metrics mean absolute error **MAE** which is available via Sklearn.metrics and via the metrics mean absolute percentage error called **MAPE**.\n",
    "\n",
    "There is no inbuilt function in sci-kit learn, so i define a custom function to calculate this measure. I adjusted the commom measure in the way that i do not consider all closed days of a Filiale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#calculate mean absolute forecast error which only take actual values unequal to zero in consideration\n",
    "def mean_absolute_error_nz(actual, predicted): \n",
    "    \n",
    "    nz_1=(actual==0)\n",
    "    actual_nz=actual[nz_1==0]\n",
    "    \n",
    "    difference_nz=actual-predicted\n",
    "    difference_nz.dropna()\n",
    "    return np.mean(np.abs((difference_nz)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#calculate mean absolute percentage forecast error\n",
    "def mean_absolute_percentage_error(actual, predicted): \n",
    "    \n",
    "    nz_1=(actual==0)\n",
    "    actual_nz=actual[nz_1==0]\n",
    "    \n",
    "    difference_nz=actual-predicted\n",
    "    difference_nz.dropna()\n",
    "    return np.mean(np.abs((difference_nz) / actual_nz)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test-/Train-Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test datasets to build the model on the training dataset and forecast using the test dataset. I decide to use the first 4 years for training and the period since 01.01.2019 for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use past 4 years data to forecast the next 15 months until corona\n",
    "\n",
    "start='01.01.2016'\n",
    "duration = '31.12.2018'\n",
    "corona='15.03.2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Basismodel\n",
    "train_basis_2 = df_basis_2[:duration].copy()\n",
    "test_basis_2 = df_basis_2[duration:corona].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_2 = df_new_2[start:duration].copy()\n",
    "test_new_2 = df_new_2[duration:corona].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The moving average value can also be used directly to make predictions as a naive model and baseline for further \n",
    "on analysis. The fit would has been better if trend and seasonality components of the time series have already been removed or adjusted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving average smoothing as a forecast model\n",
    "from math import sqrt\n",
    "from numpy import mean\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1=df_basis_2.Brötchen   \n",
    "window = 3\n",
    "history_1 = [X_1[i] for i in range(window)]  \n",
    "test_1 = [X_1[i] for i in range(window, len(X_1))] \n",
    "predictions_1 = list()\n",
    "#walk forward over time steps in test\n",
    "for t in range(len(test_1)):\n",
    "      length = len(history_1)\n",
    "      yhat = mean([history_1[i] for i in range(length-window,length)]) \n",
    "      obs = test_1[t]\n",
    "      predictions_1.append(yhat)\n",
    "      history_1.append(obs)\n",
    "\n",
    "X_2=df_basis_2.Stückgebäck   \n",
    "window = 3\n",
    "history_2 = [X_2[i] for i in range(window)]  \n",
    "test_2 = [X_2[i] for i in range(window, len(X_2))] \n",
    "predictions_2 = list()\n",
    "#walk forward over time steps in test\n",
    "for t in range(len(test_2)):\n",
    "      length = len(history_2)\n",
    "      yhat = mean([history_2[i] for i in range(length-window,length)]) \n",
    "      obs = test_2[t]\n",
    "      predictions_2.append(yhat)\n",
    "      history_2.append(obs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_1=(mean_absolute_error(test_1, predictions_1)) \n",
    "print('Ergebnis der Baseline for articlegroup Brötchen:')\n",
    "print('Mean absolute Error MAE %.3f' % mae_1)\n",
    "# plot\n",
    "plt.figure(figsize=(15,5))\n",
    "pyplot.plot(test_1)\n",
    "pyplot.plot(predictions_1, color='red') \n",
    "pyplot.show()\n",
    "# zoom plot\n",
    "plt.figure(figsize=(15,5))\n",
    "pyplot.plot(test_1[:100]) \n",
    "pyplot.plot(predictions_1[:100], color='red') \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_2=(mean_absolute_error(test_2, predictions_2)) \n",
    "print('Ergebnis der Baseline for articlegroup Stückgebäck:')\n",
    "print('Mean absolute Error  MAE %.3f' % mae_2)\n",
    "# plot\n",
    "plt.figure(figsize=(15,5))\n",
    "pyplot.plot(test_2)\n",
    "pyplot.plot(predictions_2, color='red') \n",
    "pyplot.show()\n",
    "# zoom plot\n",
    "plt.figure(figsize=(15,5))\n",
    "pyplot.plot(test_2[:100]) \n",
    "pyplot.plot(predictions_2[:100], color='red') \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basismodell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUTOARIMA to find the best Parameterkombination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**\n",
    "- `The best combination for articlegroup Brötchen is (1,0,3)x((1,0,1,7).`\n",
    "- `The best combination für Süsse_Brötchen is .`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m = 7 as data contains daily observations\n",
    "model_autoarima = auto_arima(train_basis_2['Brötchen'], seasonal=True,m=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autoarima_7 = auto_arima(train_basis_2['Süsse_Brötchen'], seasonal=True,m=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autoarima_8 = auto_arima(train_basis_2['Herzhafte_Brötchen'], seasonal=True,m=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autoarima_11 = auto_arima(train_basis_2['Stückgebäck'], seasonal=True,m=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autoarima_11.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fit\n",
    "sarima_basis_2_6 = sm.tsa.statespace.SARIMAX(train_basis_2['Brötchen'],order=(1,0,3),seasonal_order=(1,0,1,7),\n",
    "                                enforce_stationarity=True, enforce_invertibility=False,freq='D').fit()\n",
    "#sarima_basis_2_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "pred_basis_2_6 = sarima_basis_2_6.predict('01.01.2019','15.03.2020')[:]\n",
    "print('Results for Basismodel-articlegroup Brötchen:')\n",
    "print('SARIMA model MAE: {0:.2f}'.format(mean_absolute_error(test_basis_2['01.01.2019':'15.03.2020']['Brötchen'],pred_basis_2_6)))\n",
    "print('SARIMA model MAPE: {0:.2f}%'.format(mean_absolute_percentage_error(test_basis_2['01.01.2019':'15.03.2020']['Brötchen'],pred_basis_2_6)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_basis_2_6.plot_diagnostics(figsize=(15, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fit\n",
    "sarima_basis_2_7 = sm.tsa.statespace.SARIMAX(train_basis_2['Süsse_Brötchen'],order=(1,0,3),seasonal_order=(1,0,1,7),\n",
    "                                enforce_stationarity=False, enforce_invertibility=False,freq='D').fit()\n",
    "#sarima_basis_2_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_basis_2_7 = sarima_basis_2_7.predict('01.01.2019','15.03.2020')[:]\n",
    "print('Results for Basismodel-articlegroup Süsse Brötchen:')\n",
    "print('SARIMA model MAE: {0:.2f}'.format(mean_absolute_error(test_basis_2['01.01.2019':'15.03.2020']['Süsse_Brötchen'],pred_basis_2_7)))\n",
    "print('SARIMA model MAPE: {0:.2f}%'.format(mean_absolute_percentage_error(test_basis_2['01.01.2019':'15.03.2020']['Süsse_Brötchen'],pred_basis_2_7)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fit\n",
    "sarima_basis_2_8 = sm.tsa.statespace.SARIMAX(train_basis_2['Herzhafte_Brötchen'],order=(0,1,1),seasonal_order=(0,0,1,7),\n",
    "                                enforce_stationarity=False, enforce_invertibility=False,freq='D').fit()\n",
    "#sarima_basis_2_8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_basis_2_8 = sarima_basis_2_8.predict('01.01.2019','15.03.2020')[:]\n",
    "\n",
    "print('Results for Basismodel-articlegroup Stückgebäck:')\n",
    "print('SARIMA model MAE for Basismodel Stückgebäck: {0:.2f}'.format(mean_absolute_error(test_basis_2['01.01.2019':'15.03.2020']['Herzhafte_Brötchen'],pred_basis_2_8)))\n",
    "print('SARIMA model MAPE for Basismodel Stückgebäck: {0:.2f}%'.format(mean_absolute_percentage_error(test_basis_2['01.01.2019':'15.03.2020']['Herzhafte_Brötchen'],pred_basis_2_8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fit\n",
    "sarima_basis_2_11 = sm.tsa.statespace.SARIMAX(train_basis_2['Stückgebäck'],order=(1,1,1),\n",
    "                                enforce_stationarity=False, enforce_invertibility=False,freq='D').fit()\n",
    "#sarima_basis_2_11.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_2_11 = sarima_basis_2_11.predict('01.01.2019','15.03.2020')[:]\n",
    "print('Results for Basismodel-articlegroup Stückgebäck:')\n",
    "print('SARIMA model MAE for Basismodel Stückgebäck: {0:.2f}'.format(mean_absolute_error(test_basis_2['01.01.2019':'15.03.2020']['Stückgebäck'],pred_basis_2_11)))\n",
    "print('SARIMA model MAPE for Basismodel Stückgebäck: {0:.2f}%'.format(mean_absolute_percentage_error(test_basis_2['01.01.2019':'15.03.2020']['Stückgebäck'],pred_basis_2_11)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARIMAX Model with exogenen Faktoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog_train_new_2=train_new_2.iloc[:,18:19][start:duration]\n",
    "exog_train_new_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fit\n",
    "sarima_new_2_6 = sm.tsa.statespace.SARIMAX(train_new_2['Brötchen'],order=(1,0,3),seasonal_order=(1,0,1,7),\n",
    "                                             exog = exog_train_new_2,enforce_stationarity=False, enforce_invertibility=False,freq='D').fit()\n",
    "sarima_new_2_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_new_2_6 = sarima_new_2_6.predict('01.01.2019','15.03.2020')[:]\n",
    "print('Results for Basismodel-articlegroup Brötchen:')\n",
    "print('SARIMA model MAE: {0:.2f}'.format(mean_absolute_error(test_new_2['01.01.2019':'15.03.2020']['Brötchen'],pred_new_2_6)))\n",
    "print('SARIMA model MAPE: {0:.2f}%'.format(mean_absolute_percentage_error(test_new_2['01.01.2019':'15.03.2020']['Brötchen'],pred_new_2_6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VARMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROPHET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holt Winter’s Exponential Smoothing (HWES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "527.778px",
    "left": "50px",
    "top": "110.052px",
    "width": "282.778px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
