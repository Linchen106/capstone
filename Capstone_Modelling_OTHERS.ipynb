{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1. Setup](#Setup)\n",
    "\n",
    "[2. Data Cleaning and Preparation](#Data-Cleaning-&-Preparation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup & Import¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import basic system functions\n",
    "import os\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "import random\n",
    "\n",
    "#import libraries for data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import libraries for plotting data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as mplt\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from pandas.plotting import autocorrelation_plot, lag_plot\n",
    "from scipy import signal\n",
    "# If you want a style choose one\n",
    "#plt.style.use('Solarize_Light2')\n",
    "#plt.style.use('tableau-colorblind10')\n",
    "NF_ORANGE = '#ff5a36'\n",
    "NF_BLUE = '#163251'\n",
    "\n",
    "\n",
    "\n",
    "#import libraries for time series analysis\n",
    "from fbprophet import Prophet\n",
    "from fbprophet.plot import add_changepoints_to_plot\n",
    "from fbprophet.diagnostics import cross_validation\n",
    "from fbprophet.diagnostics import performance_metrics\n",
    "from fbprophet.plot import plot_cross_validation_metric\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "from pylab import rcParams\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from pmdarima.arima import auto_arima\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.api import SimpleExpSmoothing\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#import libraries for statistics\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from fbprophet.diagnostics import performance_metrics\n",
    "from fbprophet.diagnostics import cross_validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "from datetime import datetime\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2= pd.read_csv(\"df_new_2.csv\")\n",
    "df_2_clean= pd.read_csv(\"data_2_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "df_2_clean.drop(columns=['Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df= pd.read_csv(\"/Users/brittarover/Capstone/Meteolytics/meteolytix_Artikelgruppen_Umsatz_verschiedeneStandorte.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>Weizenbrot</th>\n",
       "      <th>Mischbrot</th>\n",
       "      <th>Vollkornbrot</th>\n",
       "      <th>Stangenbrote</th>\n",
       "      <th>Spezialbrot</th>\n",
       "      <th>Brötchen</th>\n",
       "      <th>Süsse_Brötchen</th>\n",
       "      <th>Herzhafte_Brötchen</th>\n",
       "      <th>KonditoreiBlech</th>\n",
       "      <th>...</th>\n",
       "      <th>Closed</th>\n",
       "      <th>Outlier</th>\n",
       "      <th>New_Years_Eve</th>\n",
       "      <th>Feiertag_DE</th>\n",
       "      <th>Ostern</th>\n",
       "      <th>Holidays_SH</th>\n",
       "      <th>SUMMER_SH</th>\n",
       "      <th>Niederschlag</th>\n",
       "      <th>Sonne_h</th>\n",
       "      <th>Temperatur_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>88.02375</td>\n",
       "      <td>84.63319</td>\n",
       "      <td>115.157621</td>\n",
       "      <td>58.999279</td>\n",
       "      <td>66.687652</td>\n",
       "      <td>505.565569</td>\n",
       "      <td>235.597443</td>\n",
       "      <td>87.759013</td>\n",
       "      <td>66.333083</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Datum  Weizenbrot  Mischbrot  Vollkornbrot  Stangenbrote  Spezialbrot  \\\n",
       "0  2015-01-01     0.00000    0.00000      0.000000      0.000000     0.000000   \n",
       "1  2015-01-02    88.02375   84.63319    115.157621     58.999279    66.687652   \n",
       "\n",
       "     Brötchen  Süsse_Brötchen  Herzhafte_Brötchen  KonditoreiBlech  ...  \\\n",
       "0    0.000000        0.000000            0.000000         0.000000  ...   \n",
       "1  505.565569      235.597443           87.759013        66.333083  ...   \n",
       "\n",
       "   Closed  Outlier  New_Years_Eve  Feiertag_DE  Ostern  Holidays_SH  \\\n",
       "0       1        0              0            1     0.0          1.0   \n",
       "1       0        0              0            0     0.0          1.0   \n",
       "\n",
       "   SUMMER_SH  Niederschlag  Sonne_h  Temperatur_max  \n",
       "0        0.0           8.0      0.0             6.2  \n",
       "1        0.0           2.2      0.7             9.5  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2_clean.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1979 entries, 0 to 1978\n",
      "Data columns (total 31 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Datum               1979 non-null   object \n",
      " 1   Weizenbrot          1979 non-null   float64\n",
      " 2   Mischbrot           1979 non-null   float64\n",
      " 3   Vollkornbrot        1979 non-null   float64\n",
      " 4   Stangenbrote        1979 non-null   float64\n",
      " 5   Spezialbrot         1979 non-null   float64\n",
      " 6   Brötchen            1979 non-null   float64\n",
      " 7   Süsse_Brötchen      1979 non-null   float64\n",
      " 8   Herzhafte_Brötchen  1979 non-null   float64\n",
      " 9   KonditoreiBlech     1979 non-null   float64\n",
      " 10  Stückgebäck         1979 non-null   float64\n",
      " 11  Blechkuchen         1979 non-null   float64\n",
      " 12  Weihnachtsartikel   1979 non-null   float64\n",
      " 13  Wochentag           1979 non-null   int64  \n",
      " 14  Tag                 1979 non-null   int64  \n",
      " 15  Jahr                1979 non-null   int64  \n",
      " 16  Monat               1979 non-null   int64  \n",
      " 17  Gesamt              1979 non-null   float64\n",
      " 18  Wochenende_flag     1979 non-null   int64  \n",
      " 19  Season              1979 non-null   int64  \n",
      " 20  Christmas           1979 non-null   int64  \n",
      " 21  Closed              1979 non-null   int64  \n",
      " 22  Outlier             1979 non-null   int64  \n",
      " 23  New_Years_Eve       1979 non-null   int64  \n",
      " 24  Feiertag_DE         1979 non-null   int64  \n",
      " 25  Ostern              1979 non-null   float64\n",
      " 26  Holidays_SH         1979 non-null   float64\n",
      " 27  SUMMER_SH           1979 non-null   float64\n",
      " 28  Niederschlag        1979 non-null   float64\n",
      " 29  Sonne_h             1979 non-null   float64\n",
      " 30  Temperatur_max      1979 non-null   float64\n",
      "dtypes: float64(19), int64(11), object(1)\n",
      "memory usage: 479.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_2_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1979, 33)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['Datum'] = pd.to_datetime(df_2['Datum'])\n",
    "df_2_clean['Datum'] = pd.to_datetime(df_2_clean['Datum'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basis_2=df_2.iloc[:,1:13]\n",
    "df_basis_2_clean=df_2_clean.iloc[:,1:13]\n",
    "df_basis_2_dum=df_2_dum.iloc[:,1:13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dummy= pd.get_dummies(df_2_clean['Monat'], prefix='M', drop_first=True)\n",
    "weekday_dummy= pd.get_dummies(df_2_clean['Wochentag'], prefix='W', drop_first=True)\n",
    "season_dummy=pd.get_dummies(df_2_clean['Season'], prefix='S', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_dum = df_2_clean.drop(['Tag','Monat','Wochentag','Jahr','Season'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_dum = pd.concat([df_2_dum,month_dummy,weekday_dummy,season_dummy], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_dum.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brückentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brückentage= pd.DataFrame({'date':pd.date_range('2019-05-02', '2019-05-05')})\n",
    "Brückentage = Brückentage.append(pd.DataFrame({'date':pd.date_range('2019-05-31', '2019-06-02')}))\n",
    "Brückentage = Brückentage.append(pd.DataFrame({'date':pd.date_range('2019-10-04', '2019-10-06')}))\n",
    "Brückentage = Brückentage.append(pd.DataFrame({'date':pd.date_range('2019-12-27', '2019-12-30')}))\n",
    "Brückentage = Brückentage.append(pd.DataFrame({'date':pd.date_range('2018-04-28', '2018-05-01')}))\n",
    "Brückentage = Brückentage.append(pd.DataFrame({'date':pd.date_range('2018-05-10', '2018-05-13')}))\n",
    "Brückentage = Brückentage.append(pd.DataFrame({'date':pd.date_range('2018-10-03', '2018-10-08')}))\n",
    "Brückentage = Brückentage.append(pd.DataFrame({'date':pd.date_range('2018-12-27', '2018-12-30')}))\n",
    "Brückentage = Brückentage.append(pd.DataFrame({'date':pd.date_range('2017-04-30', '2017-05-01')}))\n",
    "Brückentage = Brückentage.append(pd.DataFrame({'date':pd.date_range('2017-05-25', '2017-05-28')}))\n",
    "Brückentage = Brückentage.append(pd.DataFrame({'date':pd.date_range('2017-09-29', '2017-10-03')}))\n",
    "Brückentage = Brückentage.append(pd.DataFrame({'date':pd.date_range('2017-10-28', '2017-10-31')}))\n",
    "Brückentage = Brückentage.append(pd.DataFrame({'date':pd.date_range('2017-12-27', '2017-12-30')}))\n",
    "Brückentage = Brückentage.append(pd.DataFrame({'date':pd.date_range('2016-12-27', '2016-12-30')}))\n",
    "Brückentage = Brückentage.append(pd.DataFrame({'date':pd.date_range('2016-05-05', '2017-05-08')}))\n",
    "Brückentage = Brückentage.append(pd.DataFrame({'date':pd.date_range('2016-09-30', '2016-10-03')}))\n",
    "\n",
    "\n",
    "Brückentage['Datum']=Brückentage['date'].apply(lambda x: x.strftime(format = \"%Y-%m-%d\"))\n",
    "liste_Brückentage=Brückentage['Datum'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of new column Brückentage\n",
    "df_2_dum['Brückentage']=df_2_dum['Datum'].apply(lambda x: 1 if x.strftime(format = \"%Y-%m-%d\") in \n",
    "                                                liste_Brückentage else 0)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kieler Woche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kieler_woche= pd.DataFrame({'date':pd.date_range('2019-06-22', '2019-06-30')})\n",
    "kieler_woche = kieler_woche.append(pd.DataFrame({'date':pd.date_range('2018-06-16', '2018-06-24')}))\n",
    "kieler_woche = kieler_woche.append(pd.DataFrame({'date':pd.date_range('2017-06-17', '2017-06-25')}))\n",
    "kieler_woche = kieler_woche.append(pd.DataFrame({'date':pd.date_range('2016-06-18', '2016-06-26')}))\n",
    "kieler_woche = kieler_woche.append(pd.DataFrame({'date':pd.date_range('2015-06-20', '2015-06-28')}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kieler_woche['Datum']=kieler_woche['date'].apply(lambda x: x.strftime(format = \"%Y-%m-%d\"))\n",
    "liste_kw=kieler_woche['Datum'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of new column Kieler Woche\n",
    "df_2_dum['Kieler_Woche']=df_2_dum['Datum'].apply(lambda x: 1 if x.strftime(format = \"%Y-%m-%d\") in liste_kw else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timerelated Features for Salesvolumne in the past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Values of the previous week and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "articlelist=df_basis_2_dum.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For multiple Columns and also Dataframes\n",
    "var=['Gesamt']\n",
    "numbers=[7,364]\n",
    "\n",
    "for i in var:\n",
    "    for j in numbers:\n",
    "       df_2_dum[\"%s_%d\" % (i,j)]=df_2_dum[i].shift(j)\n",
    "       df_2_dum[\"%s_%d\" % (i,j)].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For multiple Columns and also Dataframes\n",
    "#var=['Brötchen','Süsse_Brötchen','Herzhafte_Brötchen']\n",
    "numbers=[7,364]\n",
    "\n",
    "for i in articlelist:\n",
    "    for j in numbers:\n",
    "       df_2_dum[\"%s_%d\" % (i,j)]=df_2_clean[i].shift(j)\n",
    "       df_2_dum[\"%s_%d\" % (i,j)].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean and max-Values for Weekday and Monthly Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**\n",
    "- `Mean and Maxvalues have no significant impact to the correlation. I need to do it for Months and Weekdays.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition on weekldaybase\n",
    "def Brötchen_mean(x):\n",
    "    return df_2.groupby('Wochentag')['Brötchen'].mean()[x]\n",
    "def Brötchen_max(x):\n",
    "    return df_2.groupby('Wochentag')['Brötchen'].max()[x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For multiple Columns and also Dataframes\n",
    "var=['Süsse_Brötchen','Herzhafte_Brötchen']\n",
    "\n",
    "\n",
    "for i in var:\n",
    "    name=i+ \"_mean\"\n",
    "    \n",
    "    def name(x):\n",
    "        return df_2.groupby('Wochentag')['%s' % (i)].mean()[x]\n",
    "\n",
    "    df_2['%s_mean_WD' % (i)]=df_2['Wochentag'].apply(lambda x:  name(x))\n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For multiple Columns and also Dataframes\n",
    "var=['Süsse_Brötchen','Herzhafte_Brötchen']\n",
    "\n",
    "\n",
    "for i in var:\n",
    "    name=i+ \"_max\"\n",
    "    \n",
    "    def name(x):\n",
    "        return df_2.groupby('Wochentag')['%s' % (i)].mean()[x]\n",
    "\n",
    "    df_2['%s_max_WD' % (i)]=df_2['Wochentag'].apply(lambda x:  name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Brötchen_mean_M(x):\n",
    "    return df_2.groupby('Monat')['Brötchen'].mean()[x]\n",
    "def Brötchen_max_M(x):\n",
    "    return df_2.groupby('Monat')['Brötchen'].max()[x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['Brötchen_mean_M']=df_2['Monat'].apply(lambda x:  Brötchen_mean_M(x))\n",
    "df_2['Brötchen_max_M']=df_2['Monat'].apply(lambda x:  Brötchen_max_M(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For multiple Columns and also Dataframes\n",
    "var=['Süsse_Brötchen','Herzhafte_Brötchen']\n",
    "\n",
    "for i in var:\n",
    "    name=i+ \"_mean\"\n",
    "    \n",
    "    def name(x):\n",
    "        return df_2.groupby('Monat')['%s' % (i)].mean()[x]\n",
    "\n",
    "    df_2['%s_mean_M' % (i)]=df_2['Monat'].apply(lambda x:  name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For multiple Columns and also Dataframes\n",
    "var=['Süsse_Brötchen','Herzhafte_Brötchen']\n",
    "\n",
    "\n",
    "for i in var:\n",
    "    name=i+ \"_max\"\n",
    "    \n",
    "    def name(x):\n",
    "        return df_2.groupby('Monat')['%s' % (i)].mean()[x]\n",
    "\n",
    "    df_2['%s_max_M' % (i)]=df_2['Monat'].apply(lambda x:  name(x))\n",
    "                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valuation of agg.Values\n",
    "df_2.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation für Brötchen\n",
    "basis=num_df.corr(method='pearson')['Brötchen'].sort_values(axis=0, ascending=False)\n",
    "#basis.plot(kind='bar',figsize=(10,8),title='Korrelation nach Pearson für Brötchen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we create a new DataFrame with only numerical features\n",
    "numerics = ['int64', 'float64']\n",
    "\n",
    "num_df = df_2.select_dtypes(include=numerics)\n",
    "\n",
    "#Korrelationsanalyse\n",
    "mask = np.triu( num_df.corr())\n",
    "plt.figure(figsize=(30,18))\n",
    "plt.title('Correlation of variables')\n",
    "ax=sns.heatmap(num_df.corr(),vmax=1.0,annot=True,mask=mask,cmap='coolwarm')\n",
    "plt.savefig('correlogram_simple.png')\n",
    "ax.set_ylim((0,30))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.to_csv(\"df_new_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checks Timeseries & Setup Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_newmodel_2 = df_2.set_index('Datum')\n",
    "df_newmodel_2_dum=df_2_dum.set_index('Datum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new_1_index=df_newmodel_1.set_index('Datum')\n",
    "#df_new_2_index=df_newmodel_2.set_index('Datum')\n",
    "#df_new_3_index=df_newmodel_1.set_index('Datum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**\n",
    "- `I choose MAE and MAPE as Performance Measures for my project.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would analyse the results from the different models via the two different metrics mean absolute error **MAE** which is available via Sklearn.metrics and via the metrics mean absolute percentage error called **MAPE**.\n",
    "\n",
    "There is no inbuilt function in sci-kit learn, so i define a custom function to calculate this measure. I adjusted the commom measure in the way that i do not consider all closed days of a Filiale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate mean absolute forecast error which only take actual values unequal to zero in consideration\n",
    "def mean_absolute_percentage_error_WZ(actual, predicted): \n",
    "    \n",
    "    actual, predicted = np.array(actual), np.array(predicted)\n",
    "    return np.mean(np.abs((actual - predicted) / actual)) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate mean absolute percentage forecast error\n",
    "def mean_absolute_percentage_error(actual, predicted): \n",
    "    \n",
    "    nz_1=(actual==0)\n",
    "    actual_nz=actual[nz_1==0]\n",
    "    \n",
    "    difference_nz=actual-predicted\n",
    "    difference_nz.dropna()\n",
    "    return np.mean(np.abs((difference_nz) / actual_nz)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate mean absolute percentage forecast error\n",
    "def mean_absolute_percentage_error_modify(actual, predicted): \n",
    "    \n",
    "    nz_1=(actual==0)\n",
    "    actual_nz=actual[nz_1==0]\n",
    "    \n",
    "    difference_nz=actual-predicted\n",
    "    difference_nz.dropna()\n",
    "    return np.mean(np.abs((difference_nz))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "def mae(actual, predict):\n",
    "    predict = np.array(predict)\n",
    "    actual = np.array(actual)\n",
    "    distance = predict - actual\n",
    "    distance_mean = distance.mean()\n",
    "    score = np.sqrt(distance_mean)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_score = make_scorer(mae, greater_is_better = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_results(y_true, y_pred):\n",
    "# Regression metrics\n",
    "    explained_variance=metrics.explained_variance_score(y_true, y_pred)\n",
    "    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) \n",
    "    mse=metrics.mean_squared_error(y_true, y_pred) \n",
    "    mean_squared_log_error=metrics.mean_squared_log_error(y_true, y_pred)\n",
    "    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2=metrics.r2_score(y_true, y_pred)\n",
    "    print('explained_variance: ', round(explained_variance,4))    \n",
    "    print('mean_squared_log_error: ', round(mean_squared_log_error,4))\n",
    "    print('r2: ', round(r2,4))\n",
    "    print('MAE: ', round(mean_absolute_error,4))\n",
    "    print('MAPE', round(mean_absolute_percentage_error,4))\n",
    "    print('MSE: ', round(mse,4))\n",
    "    print('RMSE: ', round(np.sqrt(mse),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test-/Train-Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test datasets to build the model on the training dataset and forecast using the test dataset. I decide to use the first 4 years for training and the period since 01.01.2019 for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use past 4 years data to forecast the next 15 months until corona\n",
    "\n",
    "start_train='01.01.2016'\n",
    "end_train = '31.12.2018'\n",
    "start_test='01.01.2019'\n",
    "corona='15.03.2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Basismodel\n",
    "train_basis_2 = df_newmodel_2_dum[:end_train].copy()\n",
    "test_basis_2 = df_newmodel_2_dum[end_train:corona].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2 = df_newmodel_2_dum[start_train:end_train].copy()\n",
    "test_2 = df_newmodel_2_dum[start_test:corona].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The moving average value can also be used directly to make predictions as a naive model and baseline for further \n",
    "on analysis. The fit would has been better if trend and seasonality components of the time series have already been removed or adjusted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving average smoothing as a forecast model\n",
    "from math import sqrt\n",
    "from numpy import mean\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_Baseline= pd.read_csv(\"df_results_Baseline\")\n",
    "df_results_Baseline.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "df_results_Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_train='01.01.2016'\n",
    "end_train = '31.12.2018'\n",
    "start_test='01.01.2019'\n",
    "corona='15.03.2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basismodel\n",
    "train_2 = df_2_dum[365:1461]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 = df_2_dum[1462:1901]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1096 entries, 365 to 1460\n",
      "Data columns (total 74 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   Datum                   1096 non-null   datetime64[ns]\n",
      " 1   Weizenbrot              1096 non-null   float64       \n",
      " 2   Mischbrot               1096 non-null   float64       \n",
      " 3   Vollkornbrot            1096 non-null   float64       \n",
      " 4   Stangenbrote            1096 non-null   float64       \n",
      " 5   Spezialbrot             1096 non-null   float64       \n",
      " 6   Brötchen                1096 non-null   float64       \n",
      " 7   Süsse_Brötchen          1096 non-null   float64       \n",
      " 8   Herzhafte_Brötchen      1096 non-null   float64       \n",
      " 9   KonditoreiBlech         1096 non-null   float64       \n",
      " 10  Stückgebäck             1096 non-null   float64       \n",
      " 11  Blechkuchen             1096 non-null   float64       \n",
      " 12  Weihnachtsartikel       1096 non-null   float64       \n",
      " 13  Gesamt                  1096 non-null   float64       \n",
      " 14  Wochenende_flag         1096 non-null   int64         \n",
      " 15  Christmas               1096 non-null   int64         \n",
      " 16  Closed                  1096 non-null   int64         \n",
      " 17  Outlier                 1096 non-null   int64         \n",
      " 18  New_Years_Eve           1096 non-null   int64         \n",
      " 19  Feiertag_DE             1096 non-null   int64         \n",
      " 20  Ostern                  1096 non-null   float64       \n",
      " 21  Holidays_SH             1096 non-null   float64       \n",
      " 22  SUMMER_SH               1096 non-null   float64       \n",
      " 23  Niederschlag            1096 non-null   float64       \n",
      " 24  Sonne_h                 1096 non-null   float64       \n",
      " 25  Temperatur_max          1096 non-null   float64       \n",
      " 26  M_2                     1096 non-null   uint8         \n",
      " 27  M_3                     1096 non-null   uint8         \n",
      " 28  M_4                     1096 non-null   uint8         \n",
      " 29  M_5                     1096 non-null   uint8         \n",
      " 30  M_6                     1096 non-null   uint8         \n",
      " 31  M_7                     1096 non-null   uint8         \n",
      " 32  M_8                     1096 non-null   uint8         \n",
      " 33  M_9                     1096 non-null   uint8         \n",
      " 34  M_10                    1096 non-null   uint8         \n",
      " 35  M_11                    1096 non-null   uint8         \n",
      " 36  M_12                    1096 non-null   uint8         \n",
      " 37  W_1                     1096 non-null   uint8         \n",
      " 38  W_2                     1096 non-null   uint8         \n",
      " 39  W_3                     1096 non-null   uint8         \n",
      " 40  W_4                     1096 non-null   uint8         \n",
      " 41  W_5                     1096 non-null   uint8         \n",
      " 42  W_6                     1096 non-null   uint8         \n",
      " 43  S_2                     1096 non-null   uint8         \n",
      " 44  S_3                     1096 non-null   uint8         \n",
      " 45  S_4                     1096 non-null   uint8         \n",
      " 46  Brückentage             1096 non-null   int64         \n",
      " 47  Kieler_Woche            1096 non-null   int64         \n",
      " 48  Gesamt_7                1096 non-null   float64       \n",
      " 49  Gesamt_364              1096 non-null   float64       \n",
      " 50  Weizenbrot_7            1096 non-null   float64       \n",
      " 51  Weizenbrot_364          1096 non-null   float64       \n",
      " 52  Mischbrot_7             1096 non-null   float64       \n",
      " 53  Mischbrot_364           1096 non-null   float64       \n",
      " 54  Vollkornbrot_7          1096 non-null   float64       \n",
      " 55  Vollkornbrot_364        1096 non-null   float64       \n",
      " 56  Stangenbrote_7          1096 non-null   float64       \n",
      " 57  Stangenbrote_364        1096 non-null   float64       \n",
      " 58  Spezialbrot_7           1096 non-null   float64       \n",
      " 59  Spezialbrot_364         1096 non-null   float64       \n",
      " 60  Brötchen_7              1096 non-null   float64       \n",
      " 61  Brötchen_364            1096 non-null   float64       \n",
      " 62  Süsse_Brötchen_7        1096 non-null   float64       \n",
      " 63  Süsse_Brötchen_364      1096 non-null   float64       \n",
      " 64  Herzhafte_Brötchen_7    1096 non-null   float64       \n",
      " 65  Herzhafte_Brötchen_364  1096 non-null   float64       \n",
      " 66  KonditoreiBlech_7       1096 non-null   float64       \n",
      " 67  KonditoreiBlech_364     1096 non-null   float64       \n",
      " 68  Stückgebäck_7           1096 non-null   float64       \n",
      " 69  Stückgebäck_364         1096 non-null   float64       \n",
      " 70  Blechkuchen_7           1096 non-null   float64       \n",
      " 71  Blechkuchen_364         1096 non-null   float64       \n",
      " 72  Weihnachtsartikel_7     1096 non-null   float64       \n",
      " 73  Weihnachtsartikel_364   1096 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(45), int64(8), uint8(20)\n",
      "memory usage: 483.9 KB\n"
     ]
    }
   ],
   "source": [
    "train_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_2.iloc[:,1:13].columns:\n",
    "     train_2[i]=train_2[i].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_2.iloc[:,1:13].columns:\n",
    "     test_2[i]=test_2[i].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_2_1=train_2['Weizenbrot']\n",
    "y_train_2_2=train_2['Mischbrot']\n",
    "y_train_2_3=train_2['Vollkornbrot']\n",
    "y_train_2_4=train_2['Spezialbrot']\n",
    "y_train_2_5=train_2['Stangenbrote']\n",
    "y_train_2_6=train_2['Brötchen']\n",
    "y_train_2_7=train_2['Süsse_Brötchen']\n",
    "y_train_2_8=train_2['Herzhafte_Brötchen']\n",
    "y_train_2_9=train_2['KonditoreiBlech']\n",
    "y_train_2_10=train_2['Stückgebäck']\n",
    "y_train_2_11=train_2['Blechkuchen']\n",
    "y_train_2_12=train_2['Weihnachtsartikel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_2_1=test_2['Weizenbrot']\n",
    "y_test_2_2=test_2['Mischbrot']\n",
    "y_test_2_3=test_2['Vollkornbrot']\n",
    "y_test_2_4=test_2['Spezialbrot']\n",
    "y_test_2_5=test_2['Stangenbrote']\n",
    "y_test_2_6=test_2['Brötchen']\n",
    "y_test_2_7=test_2['Süsse_Brötchen']\n",
    "y_test_2_8=test_2['Herzhafte_Brötchen']\n",
    "y_test_2_9=test_2['KonditoreiBlech']\n",
    "y_test_2_10=test_2['Stückgebäck']\n",
    "y_test_2_11=test_2['Blechkuchen']\n",
    "y_test_2_12=test_2['Weihnachtsartikel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1096, 29) (439, 29)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_2_6.shape, X_test_2_6.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365      0\n",
       "366    513\n",
       "367    458\n",
       "368    286\n",
       "369    308\n",
       "Name: Brötchen, dtype: int64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_2_6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basismodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_Random_Forest = pd.DataFrame( \n",
    "                  columns=['Model', 'Label','MAE','MAPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_Random_Forest.to_csv(\"df_results_Random_Forest_basis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_Random_Forest\n",
    "#.sort_values(['Label','MAPE']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weizenbrot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_1=train_2.iloc[:,np.r_[14,16,17,19,26:45]]\n",
    "X_test_2_1=test_2.iloc[:,np.r_[14,16,17,19,26:45]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_1\n",
    "X_test=X_test_2_1\n",
    "y_train=y_train_2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of features 23\n",
      "Average number of nodes 231\n",
      "Average maximum depth 18\n"
     ]
    }
   ],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_1= forest.predict(X_test)\n",
    "\n",
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]\n",
    "\n",
    "for ind_tree in forest.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der MAE für Weizenbrot beträgt:11.261958997722095\n",
      "Der MAPE für Weizenbrot beträgt:19.946601615214163\n"
     ]
    }
   ],
   "source": [
    "train_rf_predictions = forest.predict(X_train)\n",
    "train_rf_probs = forest.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest.predict(X_test)\n",
    "rf_probs = forest.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_1 = mean_absolute_error(y_test_2_1,y_pred_rf_2_1)\n",
    "MAE_mod=mean_absolute_percentage_error_modify(y_test_2_1,y_pred_rf_2_1)\n",
    "MAPE_1=mean_absolute_percentage_error(y_test_2_1,y_pred_rf_2_1)\n",
    "print(f'Der MAE für Weizenbrot beträgt:{MAE_1}')\n",
    "#print(f'Der MAE_mod für Weizenbrot beträgt:{MAE_mod}')\n",
    "print(f'Der MAPE für Weizenbrot beträgt:{MAPE_1}')\n",
    "df_results_Random_Forest.loc['1',:] = ['Random_Forest-Basis','Weizenbrot',MAE_1,MAPE_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mischbrot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_2=train_2.iloc[:,np.r_[14,16,17,19,26:45]]\n",
    "X_test_2_2=test_2.iloc[:,np.r_[14,16,17,19,26:45]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_2\n",
    "X_test=X_test_2_2\n",
    "y_train=y_train_2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of features 23\n",
      "Average number of nodes 233\n",
      "Average maximum depth 17\n"
     ]
    }
   ],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_2= forest.predict(X_test)\n",
    "\n",
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]\n",
    "\n",
    "for ind_tree in forest.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der MAE für Mischbrot beträgt:13.947608200455582\n",
      "Der MAPE für Mischbrot beträgt:20.771600093615174\n"
     ]
    }
   ],
   "source": [
    "train_rf_predictions = forest.predict(X_train)\n",
    "train_rf_probs = forest.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest.predict(X_test)\n",
    "rf_probs = forest.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_2 = mean_absolute_error(y_test_2_2,y_pred_rf_2_2)\n",
    "MAE_mod=mean_absolute_percentage_error_modify(y_test_2_2,y_pred_rf_2_2)\n",
    "MAPE_2=mean_absolute_percentage_error(y_test_2_2,y_pred_rf_2_2)\n",
    "print(f'Der MAE für Mischbrot beträgt:{MAE_2}')\n",
    "#print(f'Der MAE_mod für Weizenbrot beträgt:{MAE_mod}')\n",
    "print(f'Der MAPE für Mischbrot beträgt:{MAPE_2}')\n",
    "df_results_Random_Forest.loc['2',:] = ['Random_Forest-Basis','Mischbrot',MAE_2,MAPE_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vollkornbrot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_3=train_2.iloc[:,np.r_[14,16,17,19,26:46]]\n",
    "X_test_2_3=test_2.iloc[:,np.r_[14,16,17,19,26:46]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_3\n",
    "X_test=X_test_2_3\n",
    "y_train=y_train_2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of features 24\n",
      "Average number of nodes 249\n",
      "Average maximum depth 17\n"
     ]
    }
   ],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_3 = forest.predict(X_test)\n",
    "\n",
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]\n",
    "\n",
    "for ind_tree in forest.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der MAE für Vollkornbrot beträgt:24.59908883826879\n",
      "Der MAPE für Vollkornbrot beträgt:19.608865755704617\n"
     ]
    }
   ],
   "source": [
    "train_rf_predictions = forest.predict(X_train)\n",
    "train_rf_probs = forest.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest.predict(X_test)\n",
    "rf_probs = forest.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_3 = mean_absolute_error(y_test_2_3,y_pred_rf_2_3)\n",
    "MAE_mod=mean_absolute_percentage_error_modify(y_test_2_3,y_pred_rf_2_3)\n",
    "MAPE_3=mean_absolute_percentage_error(y_test_2_3,y_pred_rf_2_3)\n",
    "print(f'Der MAE für Vollkornbrot beträgt:{MAE_3}')\n",
    "#print(f'Der MAE_mod für Vollkornbrot beträgt:{MAE_mod}')\n",
    "print(f'Der MAPE für Vollkornbrot beträgt:{MAPE_3}')\n",
    "df_results_Random_Forest.loc['3',:] = ['Random_Forest-Basis','Vollkornbrot',MAE_3,MAPE_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spezialbrot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_4=train_2.iloc[:,np.r_[14,27:43]]\n",
    "X_test_2_4=test_2.iloc[:,np.r_[14,27:43]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_4=train_2.iloc[:,np.r_[14:43]]\n",
    "X_test_2_4=test_2.iloc[:,np.r_[14:43]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_4\n",
    "X_test=X_test_2_4\n",
    "y_train=y_train_2_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of features 29\n",
      "Average number of nodes 1288\n",
      "Average maximum depth 25\n"
     ]
    }
   ],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_4 = forest.predict(X_test)\n",
    "\n",
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]\n",
    "\n",
    "for ind_tree in forest.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der MAE für Spezialbrot beträgt:22.838268792710707\n",
      "Der MAPE für Spezialbrot beträgt:36.39806982145019\n"
     ]
    }
   ],
   "source": [
    "train_rf_predictions = forest.predict(X_train)\n",
    "train_rf_probs = forest.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest.predict(X_test)\n",
    "rf_probs = forest.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_4 = mean_absolute_error(y_test_2_4,y_pred_rf_2_4)\n",
    "MAE_mod=mean_absolute_percentage_error_modify(y_test_2_4,y_pred_rf_2_4)\n",
    "MAPE_4=mean_absolute_percentage_error(y_test_2_4,y_pred_rf_2_4)\n",
    "print(f'Der MAE für Spezialbrot beträgt:{MAE_4}')\n",
    "#print(f'Der MAE_mod für Spezialbrot beträgt:{MAE_mod}')\n",
    "print(f'Der MAPE für Spezialbrot beträgt:{MAPE_4}')\n",
    "df_results_Random_Forest.loc['4',:] = ['Random_Forest-Basis','Spezialbrot',MAE_4,MAPE_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stangenbrote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_5=train_2.iloc[:,np.r_[14:47]]\n",
    "X_test_2_5=test_2.iloc[:,np.r_[14:47]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_5\n",
    "X_test=X_test_2_5\n",
    "y_train=y_train_2_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of features 33\n",
      "Average number of nodes 1320\n",
      "Average maximum depth 26\n"
     ]
    }
   ],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_5 = forest.predict(X_test)\n",
    "\n",
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]\n",
    "\n",
    "for ind_tree in forest.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der MAE für Stangenbrote beträgt:14.708428246013668\n",
      "Der MAPE für Stangenbrote beträgt:48.691470626038374\n"
     ]
    }
   ],
   "source": [
    "train_rf_predictions = forest.predict(X_train)\n",
    "train_rf_probs = forest.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest.predict(X_test)\n",
    "rf_probs = forest.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_5 = mean_absolute_error(y_test_2_5,y_pred_rf_2_5)\n",
    "MAE_mod=mean_absolute_percentage_error_modify(y_test_2_5,y_pred_rf_2_5)\n",
    "MAPE_5=mean_absolute_percentage_error(y_test_2_5,y_pred_rf_2_5)\n",
    "print(f'Der MAE für Stangenbrote beträgt:{MAE_5}')\n",
    "#print(f'Der MAE_mod für Spezialbrot beträgt:{MAE_mod}')\n",
    "print(f'Der MAPE für Stangenbrote beträgt:{MAPE_5}')\n",
    "df_results_Random_Forest.loc['5',:] = ['Random_Forest-Basis','Stangenbrote',MAE_5,MAPE_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brötchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_6=train_2.iloc[:,np.r_[14,16,17,19,21,22,25:48]]\n",
    "X_test_2_6=test_2.iloc[:,np.r_[14,16,17,19,21,22,25:48]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_6\n",
    "X_test=X_test_2_6\n",
    "y_train=y_train_2_6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest = RandomForestClassifier(random_state = 0)\n",
    "\n",
    "# Step 2: Train the model on the data\n",
    "forest.fit(X_train,y_train)\n",
    "\n",
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_6 = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of features 29\n",
      "Average number of nodes 1345\n",
      "Average maximum depth 23\n"
     ]
    }
   ],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]\n",
    "\n",
    "for ind_tree in forest.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rf_predictions = forest.predict(X_train)\n",
    "train_rf_probs = forest.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest.predict(X_test)\n",
    "rf_probs = forest.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der MAE für Brötchen beträgt:59.52847380410023\n",
      "Der MAPE für Brötchen beträgt:14.329335816436556\n"
     ]
    }
   ],
   "source": [
    "MAE_6 = mean_absolute_error(y_test_2_6,y_pred_rf_2_6)\n",
    "MAE_mod=mean_absolute_percentage_error_modify(y_test_2_6,y_pred_rf_2_6)\n",
    "MAPE_6=mean_absolute_percentage_error(y_test_2_6,y_pred_rf_2_6)\n",
    "print(f'Der MAE für Brötchen beträgt:{MAE_6}')\n",
    "#print(f'Der MAE_mod für Brötchen beträgt:{MAE_mod}')\n",
    "print(f'Der MAPE für Brötchen beträgt:{MAPE_6}')\n",
    "df_results_Random_Forest.loc['6',:] = ['Random_Forest-Basis','Brötchen',MAE_6,MAPE_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Support \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_search = { \n",
    "    'n_estimators': [20, 50, 100,200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [i for i in range(5,50)]\n",
    "}\n",
    "#'tscv = TimeSeriesSplit(n_splits=10) /  cv=tscv,\n",
    "\n",
    "#instatiate GridSearchCV fit model and make prediction\n",
    "\n",
    "gsearch = GridSearchCV(RandomForestClassifier(), param_grid=param_search, scoring = mae_score)\n",
    "gsearch.fit(X_train, y_train)\n",
    "y_pred_new = gsearch.predict(X_test)\n",
    "best_score = gsearch.best_score_\n",
    "best_model = gsearch.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = mean_absolute_error(y_test_2_6,y_pred_new)\n",
    "MAPE=mean_absolute_percentage_error(y_test_2_6,y_pred_new)\n",
    "print(f'Der MAE für Brötchen beträgt:{MAE}')\n",
    "print(f'Der MAPE für Brötchen beträgt:{MAPE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]\n",
    "\n",
    "for ind_tree in gsearch.best_estimator_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Süsse Brötchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_7=train_2.iloc[:,np.r_[14,16,17,19,21,22,25:48]]\n",
    "X_test_2_7=test_2.iloc[:,np.r_[14,16,17,19,21,22,25:48]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_7\n",
    "X_test=X_test_2_7\n",
    "y_train=y_train_2_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_7 = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]\n",
    "\n",
    "for ind_tree in forest.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rf_predictions = forest.predict(X_train)\n",
    "train_rf_probs = forest.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest.predict(X_test)\n",
    "rf_probs = forest.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_7 = mean_absolute_error(y_test_2_7,y_pred_rf_2_7)\n",
    "MAE_mod=mean_absolute_percentage_error_modify(y_test_2_7,y_pred_rf_2_7)\n",
    "MAPE_7=mean_absolute_percentage_error(y_test_2_7,y_pred_rf_2_7)\n",
    "print(f'Der MAE für Süsse Brötchen beträgt:{MAE_7}')\n",
    "#print(f'Der MAE_mod für Süsse Brötchen beträgt:{MAE_mod}')\n",
    "print(f'Der MAPE für Süsse Brötchen beträgt:{MAPE_7}')\n",
    "df_results_Random_Forest.loc['7',:] = ['Random_Forest-Basis','Süsse Brötchen',MAE_7,MAPE_7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Herzhafte Brötchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_8=train_2.iloc[:,np.r_[14,16,17,19,21,22,25:48]]\n",
    "\n",
    "\n",
    "X_test_2_8=test_2.iloc[:,np.r_[14,16,17,19,21,22,25:48]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_8=train_2.iloc[:,np.r_[14:47]]\n",
    "X_test_2_8=test_2.iloc[:,np.r_[14:47]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_8\n",
    "X_test=X_test_2_8\n",
    "y_train=y_train_2_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_8 = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_tree in forest.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rf_predictions = forest.predict(X_train)\n",
    "train_rf_probs = forest.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest.predict(X_test)\n",
    "rf_probs = forest.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_8 = mean_absolute_error(y_test_2_8,y_pred_rf_2_8)\n",
    "#MAE_mod=mean_absolute_percentage_error_modify(y_test_2_8,y_pred_rf_2_8)\n",
    "MAPE_8=mean_absolute_percentage_error(y_test_2_8,y_pred_rf_2_8)\n",
    "print(f'Der MAE für Herzhafte_Brötchen beträgt:{MAE_8}')\n",
    "#print(f'Der MAE_mod für Brötchen beträgt:{MAE_mod}')\n",
    "print(f'Der MAPE für Herzhafte_Brötchen beträgt:{MAPE_8}')\n",
    "df_results_Random_Forest.loc['8',:] = ['Random_Forest-Basis','Herzhafte_Brötchen',MAE_8,MAPE_8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KonditoreiBlech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_9=train_2.iloc[:,np.r_[26,42,22]]\n",
    "X_test_2_9=test_2.iloc[:,np.r_[26,42,22]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_9=train_2.iloc[:,np.r_[14:47]]\n",
    "X_test_2_9=test_2.iloc[:,np.r_[14:47]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_9\n",
    "X_test=X_test_2_9\n",
    "y_train=y_train_2_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_9 = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_tree in forest.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rf_predictions = forest.predict(X_train)\n",
    "train_rf_probs = forest.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest.predict(X_test)\n",
    "rf_probs = forest.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_9 = mean_absolute_error(y_test_2_9,y_pred_rf_2_9)\n",
    "#MAE_mod=mean_absolute_percentage_error_modify(y_test_2_8,y_pred_rf_2_8)\n",
    "MAPE_9=mean_absolute_percentage_error(y_test_2_9,y_pred_rf_2_9)\n",
    "print(f'Der MAE für KonditoreiBlech beträgt:{MAE_9}')\n",
    "#print(f'Der MAE_mod für Brötchen beträgt:{MAE_mod}')\n",
    "print(f'Der MAPE für KonditoreiBlech beträgt:{MAPE_9}')\n",
    "df_results_Random_Forest.loc['9',:] = ['Random_Forest-Basis','KonditoreiBlech',MAE_9,MAPE_9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stückgebäck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_9=train_2.iloc[:,np.r_[26,42,22]]\n",
    "X_test_2_9=test_2.iloc[:,np.r_[26,42,22]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_10=train_2.iloc[:,np.r_[14:47]]\n",
    "X_test_2_10=test_2.iloc[:,np.r_[14:47]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_10\n",
    "X_test=X_test_2_10\n",
    "y_train=y_train_2_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_10 = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_tree in forest.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rf_predictions = forest.predict(X_train)\n",
    "train_rf_probs = forest.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest.predict(X_test)\n",
    "rf_probs = forest.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_10 = mean_absolute_error(y_test_2_10,y_pred_rf_2_10)\n",
    "#MAE_mod=mean_absolute_percentage_error_modify(y_test_2_8,y_pred_rf_2_8)\n",
    "MAPE_10=mean_absolute_percentage_error(y_test_2_10,y_pred_rf_2_10)\n",
    "print(f'Der MAE für Stückgebäck beträgt:{MAE_10}')\n",
    "#print(f'Der MAE_mod für Brötchen beträgt:{MAE_mod}')\n",
    "print(f'Der MAPE für Stückgebäck beträgt:{MAPE_10}')\n",
    "df_results_Random_Forest.loc['10',:] = ['Random_Forest-Basis','Stückgebäck',MAE_10,MAPE_10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blechkuchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_9=train_2.iloc[:,np.r_[26,42,22]]\n",
    "X_test_2_9=test_2.iloc[:,np.r_[26,42,22]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_11=train_2.iloc[:,np.r_[14:47]]\n",
    "X_test_2_11=test_2.iloc[:,np.r_[14:47]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_11\n",
    "X_test=X_test_2_11\n",
    "y_train=y_train_2_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_11 = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_tree in forest.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rf_predictions = forest.predict(X_train)\n",
    "train_rf_probs = forest.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest.predict(X_test)\n",
    "rf_probs = forest.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_11 = mean_absolute_error(y_test_2_11,y_pred_rf_2_11)\n",
    "#MAE_mod=mean_absolute_percentage_error_modify(y_test_2_8,y_pred_rf_2_8)\n",
    "MAPE_11=mean_absolute_percentage_error(y_test_2_11,y_pred_rf_2_11)\n",
    "print(f'Der MAE für Blechkuchen beträgt:{MAE_11}')\n",
    "#print(f'Der MAE_mod für Brötchen beträgt:{MAE_mod}')\n",
    "print(f'Der MAPE für Blechkuchen beträgt:{MAPE_11}')\n",
    "df_results_Random_Forest.loc['11',:] = ['Random_Forest-Basis','Blechkuchen',MAE_11,MAPE_11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weihnachtsartikel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_9=train_2.iloc[:,np.r_[26,42,22]]\n",
    "X_test_2_9=test_2.iloc[:,np.r_[26,42,22]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_12=train_2.iloc[:,np.r_[14:47]]\n",
    "X_test_2_12=test_2.iloc[:,np.r_[14:47]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_12\n",
    "X_test=X_test_2_12\n",
    "y_train=y_train_2_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_12 = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_tree in forest.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rf_predictions = forest.predict(X_train)\n",
    "train_rf_probs = forest.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest.predict(X_test)\n",
    "rf_probs = forest.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_12 = mean_absolute_error(y_test_2_12,y_pred_rf_2_12)\n",
    "#MAE_mod=mean_absolute_percentage_error_modify(y_test_2_8,y_pred_rf_2_8)\n",
    "MAPE_12=mean_absolute_percentage_error(y_test_2_12,y_pred_rf_2_12)\n",
    "print(f'Der MAE für Weihnachtsartikel beträgt:{MAE_12}')\n",
    "#print(f'Der MAE_mod für Weihnachtsartikel beträgt:{MAE_mod}')\n",
    "print(f'Der MAPE für Weihnachtsartikel beträgt:{MAPE_12}')\n",
    "df_results_Random_Forest.loc['12',:] = ['Random_Forest-Basis','Weihnachtsartikel',MAE_12,MAPE_12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weizenbrot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_1=train_2.iloc[:,np.r_[14,16,17,19,26:45]]\n",
    "X_test_2_1=test_2.iloc[:,np.r_[14,16,17,19,26:45]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_1\n",
    "X_test=X_test_2_1\n",
    "y_train=y_train_2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest_1 = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest_1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of features 23\n",
      "Average number of nodes 231\n",
      "Average maximum depth 18\n"
     ]
    }
   ],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_1_adv= forest_1.predict(X_test)\n",
    "\n",
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]\n",
    "\n",
    "for ind_tree in forest_1.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 33 and input n_features is 23 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-234-4ebdcc2a7a9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_rf_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_rf_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrf_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrf_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \"\"\"\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    397\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 33 and input n_features is 23 "
     ]
    }
   ],
   "source": [
    "train_rf_predictions = forest.predict(X_train)\n",
    "train_rf_probs = forest.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest.predict(X_test)\n",
    "rf_probs = forest.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_1_adv = mean_absolute_error(y_test_2_1,y_pred_rf_2_1_adv)\n",
    "MAPE_1_adv=mean_absolute_percentage_error(y_test_2_1,y_pred_rf_2_1_adv)\n",
    "print(f'Der MAE für Weizenbrot beträgt:{MAE_1_adv}')\n",
    "print(f'Der MAPE für Weizenbrot beträgt:{MAPE_1_adv}')\n",
    "df_results_Random_Forest.loc['13',:] = ['Random_Forest-Advanced','Weizenbrot',MAE_1_adv,MAPE_1_adv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mischbrot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_2=train_2.iloc[:,np.r_[14,16,17,19,26:46,48,49]]\n",
    "X_test_2_2=test_2.iloc[:,np.r_[14,16,17,19,26:46,48,49]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_2\n",
    "X_test=X_test_2_2\n",
    "y_train=y_train_2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest_2 = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest_2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of features 26\n",
      "Average number of nodes 1316\n",
      "Average maximum depth 26\n"
     ]
    }
   ],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_2_adv= forest_2.predict(X_test)\n",
    "\n",
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]\n",
    "\n",
    "for ind_tree in forest_2.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der MAE für Mischbrot beträgt:15.127562642369021\n",
      "Der MAPE für Mischbrot beträgt:21.79638301540267\n"
     ]
    }
   ],
   "source": [
    "train_rf_predictions = forest_2.predict(X_train)\n",
    "train_rf_probs = forest_2.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest_2.predict(X_test)\n",
    "rf_probs = forest_2.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_2_adv = mean_absolute_error(y_test_2_2,y_pred_rf_2_2_adv)\n",
    "MAPE_2_adv=mean_absolute_percentage_error(y_test_2_2,y_pred_rf_2_2_adv)\n",
    "print(f'Der MAE für Mischbrot beträgt:{MAE_2_adv}')\n",
    "print(f'Der MAPE für Mischbrot beträgt:{MAPE_2_adv}')\n",
    "df_results_Random_Forest.loc['14',:] = ['Random_Forest-Advanced','Mischbrot',MAE_2_adv,MAPE_2_adv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vollkornbrot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_3=train_2.iloc[:,np.r_[14,16,17,19,26:46,48,49]]\n",
    "X_test_2_3=test_2.iloc[:,np.r_[14,16,17,19,26:46,48,49]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_3\n",
    "X_test=X_test_2_3\n",
    "y_train=y_train_2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest_3 = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest_3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of features 33\n",
      "Average number of nodes 248\n",
      "Average maximum depth 17\n"
     ]
    }
   ],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_3_adv = forest_3.predict(X_test)\n",
    "\n",
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]\n",
    "\n",
    "for ind_tree in forest.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der MAE für Vollkornbrot beträgt:24.170842824601365\n",
      "Der MAPE für Vollkornbrot beträgt:19.486626956545493\n"
     ]
    }
   ],
   "source": [
    "train_rf_predictions = forest_3.predict(X_train)\n",
    "train_rf_probs = forest_3.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest_3.predict(X_test)\n",
    "rf_probs = forest_3.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_3_adv = mean_absolute_error(y_test_2_3,y_pred_rf_2_3_adv)\n",
    "MAPE_3_adv=mean_absolute_percentage_error(y_test_2_3,y_pred_rf_2_3_adv)\n",
    "print(f'Der MAE für Vollkornbrot beträgt:{MAE_3_adv}')\n",
    "print(f'Der MAPE für Vollkornbrot beträgt:{MAPE_3_adv}')\n",
    "df_results_Random_Forest.loc['15',:] = ['Random_Forest-Advanced','Vollkornbrot',MAE_3_adv,MAPE_3_adv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spezialbrot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_4=train_2.iloc[:,np.r_[14,27:43,48,49]]\n",
    "X_test_2_4=test_2.iloc[:,np.r_[14,27:43,48,49]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_4=train_2.iloc[:,np.r_[14:43,48,49]]\n",
    "X_test_2_4=test_2.iloc[:,np.r_[14:43,48,49]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_4\n",
    "X_test=X_test_2_4\n",
    "y_train=y_train_2_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest_4 = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest_4.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of features 31\n",
      "Average number of nodes 1254\n",
      "Average maximum depth 26\n"
     ]
    }
   ],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_4_adv = forest_4.predict(X_test)\n",
    "\n",
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]\n",
    "\n",
    "for ind_tree in forest_4.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der MAE für Spezialbrot beträgt:23.88382687927107\n",
      "Der MAPE für Spezialbrot beträgt:38.48349483159684\n"
     ]
    }
   ],
   "source": [
    "train_rf_predictions = forest_4.predict(X_train)\n",
    "train_rf_probs = forest_4.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest_4.predict(X_test)\n",
    "rf_probs = forest_4.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_4_adv = mean_absolute_error(y_test_2_4,y_pred_rf_2_4_adv)\n",
    "MAPE_4_adv=mean_absolute_percentage_error(y_test_2_4,y_pred_rf_2_4_adv)\n",
    "print(f'Der MAE für Spezialbrot beträgt:{MAE_4_adv}')\n",
    "print(f'Der MAPE für Spezialbrot beträgt:{MAPE_4_adv}')\n",
    "df_results_Random_Forest.loc['16',:] = ['Random_Forest-Advanced','Spezialbrot',MAE_4_adv,MAPE_4_adv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stangenbrote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_5=train_2.iloc[:,np.r_[14:47,53,54]]\n",
    "X_test_2_5=test_2.iloc[:,np.r_[14:47,53,54]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_5\n",
    "X_test=X_test_2_5\n",
    "y_train=y_train_2_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest_5 = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest_5.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_5 = forest_5.predict(X_test)\n",
    "\n",
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]\n",
    "\n",
    "for ind_tree in forest_5.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rf_predictions = forest_5.predict(X_train)\n",
    "train_rf_probs = forest_5.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest_5.predict(X_test)\n",
    "rf_probs = forest_5.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_5 = mean_absolute_error(y_test_2_5,y_pred_rf_2_5)\n",
    "MAE_mod=mean_absolute_percentage_error_modify(y_test_2_5,y_pred_rf_2_5)\n",
    "MAPE_5=mean_absolute_percentage_error(y_test_2_5,y_pred_rf_2_5)\n",
    "print(f'Der MAE für Stangenbrote beträgt:{MAE_5}')\n",
    "#print(f'Der MAE_mod für Spezialbrot beträgt:{MAE_mod}')\n",
    "print(f'Der MAPE für Stangenbrote beträgt:{MAPE_5}')\n",
    "df_results_Random_Forest.loc['17',:] = ['Random_Forest-Advanced','Stangenbrote',MAE_5,MAPE_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brötchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_6=train_2.iloc[:,np.r_[14,16,17,18,19,20,21,22,25:47,57,58,71,72]]\n",
    "X_test_2_6=test_2.iloc[:,np.r_[14,16,17,18,19,20,21,22,25:47,57,58,71,72]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_6\n",
    "X_test=X_test_2_6\n",
    "y_train=y_train_2_6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest_6 = RandomForestClassifier(random_state = 0)\n",
    "\n",
    "# Step 2: Train the model on the data\n",
    "forest_6.fit(X_train,y_train)\n",
    "\n",
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_6_adv = forest_6.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]\n",
    "\n",
    "for ind_tree in forest_6.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rf_predictions = forest_6.predict(X_train)\n",
    "train_rf_probs = forest_6.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest_6.predict(X_test)\n",
    "rf_probs = forest_6.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_6_adv = mean_absolute_error(y_test_2_6,y_pred_rf_2_6_adv)\n",
    "MAPE_6_adv=mean_absolute_percentage_error(y_test_2_6,y_pred_rf_2_6_adv)\n",
    "print(f'Der MAE für Brötchen beträgt:{MAE_6_adv}')\n",
    "print(f'Der MAPE für Brötchen beträgt:{MAPE_6_adv}')\n",
    "df_results_Random_Forest.loc['42',:] = ['Random_Forest-Advanced_inclGesamt','Brötchen',MAE_6_adv,MAPE_6_adv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Süsse Brötchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_7=train_2.iloc[:,np.r_[14,16,17,18,19,20,21,22,25:47,60,71,72,73]]\n",
    "X_test_2_7=test_2.iloc[:,np.r_[14,16,17,18,19,20,21,22,25:47,60,71,72,73]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_7\n",
    "X_test=X_test_2_7\n",
    "y_train=y_train_2_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest_7 = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest_7.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_7_adv = forest_7.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]\n",
    "\n",
    "for ind_tree in forest_7.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rf_predictions = forest_7.predict(X_train)\n",
    "train_rf_probs = forest_7.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest_7.predict(X_test)\n",
    "rf_probs = forest_7.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_7_adv = mean_absolute_error(y_test_2_7,y_pred_rf_2_7_adv)\n",
    "MAPE_7_adv=mean_absolute_percentage_error(y_test_2_7,y_pred_rf_2_7_adv)\n",
    "print(f'Der MAE für Süsse Brötchen beträgt:{MAE_7_adv}')\n",
    "print(f'Der MAPE für Süsse Brötchen beträgt:{MAPE_7_adv}')\n",
    "df_results_Random_Forest.loc['43',:] = ['Random_Forest-Advanced_Gesamt','Süsse Brötchen',MAE_7_adv,MAPE_7_adv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Herzhafte Brötchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_8=train_2.iloc[:,np.r_[14,16,17,19,21,22,25:47,61,61,71,72,73]]\n",
    "X_test_2_8=test_2.iloc[:,np.r_[14,16,17,19,21,22,25:47,61,62,71,72,73]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_8=train_2.iloc[:,np.r_[14:47]]\n",
    "X_test_2_8=test_2.iloc[:,np.r_[14:47]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_8\n",
    "X_test=X_test_2_8\n",
    "y_train=y_train_2_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest_8 = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest_8.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_8_adv = forest_8.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_tree in forest_8.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rf_predictions = forest_8.predict(X_train)\n",
    "train_rf_probs = forest_8.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest_8.predict(X_test)\n",
    "rf_probs = forest_8.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_8_adv = mean_absolute_error(y_test_2_8,y_pred_rf_2_8_adv)\n",
    "#MAE_mod=mean_absolute_percentage_error_modify(y_test_2_8,y_pred_rf_2_8)\n",
    "MAPE_8_adv=mean_absolute_percentage_error(y_test_2_8,y_pred_rf_2_8_adv)\n",
    "print(f'Der MAE für Herzhafte_Brötchen beträgt:{MAE_8_adv}')\n",
    "#print(f'Der MAE_mod für Brötchen beträgt:{MAE_mod}')\n",
    "print(f'Der MAPE für Herzhafte_Brötchen beträgt:{MAPE_8_adv}')\n",
    "df_results_Random_Forest.loc['56',:] = ['Random_Forest-Advanced','Herzhafte_Brötchen',MAE_8,MAPE_8_adv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KonditoreiBlech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_9=train_2.iloc[:,np.r_[26,42,22,63,64]]\n",
    "X_test_2_9=test_2.iloc[:,np.r_[26,42,22,63,64]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_9=train_2.iloc[:,np.r_[14:47,63,64]]\n",
    "X_test_2_9=test_2.iloc[:,np.r_[14:47,63,64]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_9\n",
    "X_test=X_test_2_9\n",
    "y_train=y_train_2_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest_9 = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest_9.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_9_adv = forest_9.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_tree in forest_9.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rf_predictions = forest_9.predict(X_train)\n",
    "train_rf_probs = forest_9.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest_9.predict(X_test)\n",
    "rf_probs = forest_9.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_9_adv = mean_absolute_error(y_test_2_9,y_pred_rf_2_9)\n",
    "#MAE_mod=mean_absolute_percentage_error_modify(y_test_2_8,y_pred_rf_2_8)\n",
    "MAPE_9_adv=mean_absolute_percentage_error(y_test_2_9,y_pred_rf_2_9)\n",
    "print(f'Der MAE für KonditoreiBlech beträgt:{MAE_9_adv}')\n",
    "#print(f'Der MAE_mod für Brötchen beträgt:{MAE_mod}')\n",
    "print(f'Der MAPE für KonditoreiBlech beträgt:{MAPE_9_adv}')\n",
    "df_results_Random_Forest.loc['21',:] = ['Random_Forest-Advanced','KonditoreiBlech',MAE_9_adv,MAPE_9_adv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stückgebäck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_9=train_2.iloc[:,np.r_[26,42,22]]\n",
    "X_test_2_9=test_2.iloc[:,np.r_[26,42,22]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_10=train_2.iloc[:,np.r_[14:47,65,66]]\n",
    "X_test_2_10=test_2.iloc[:,np.r_[14:47,65,66]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_10\n",
    "X_test=X_test_2_10\n",
    "y_train=y_train_2_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest_10 = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest_10.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_10_adv = forest_10.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_tree in forest_10.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rf_predictions = forest_10.predict(X_train)\n",
    "train_rf_probs = forest_10.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest_10.predict(X_test)\n",
    "rf_probs = forest_10.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_10_adv = mean_absolute_error(y_test_2_10,y_pred_rf_2_10_adv)\n",
    "#MAE_mod=mean_absolute_percentage_error_modify(y_test_2_8,y_pred_rf_2_8)\n",
    "MAPE_10_adv=mean_absolute_percentage_error(y_test_2_10,y_pred_rf_2_10_adv)\n",
    "print(f'Der MAE für Stückgebäck beträgt:{MAE_10_adv}')\n",
    "#print(f'Der MAE_mod für Brötchen beträgt:{MAE_mod}')\n",
    "print(f'Der MAPE für Stückgebäck beträgt:{MAPE_10_adv}')\n",
    "df_results_Random_Forest.loc['22',:] = ['Random_Forest-Advanced','Stückgebäck',MAE_10_adv,MAPE_10_adv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blechkuchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_9=train_2.iloc[:,np.r_[26,42,22]]\n",
    "X_test_2_9=test_2.iloc[:,np.r_[26,42,22]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_11=train_2.iloc[:,np.r_[14:47,67,68]]\n",
    "X_test_2_11=test_2.iloc[:,np.r_[14:47,67,68]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_11\n",
    "X_test=X_test_2_11\n",
    "y_train=y_train_2_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest_11 = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest_11.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_11_adv = forest_11.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_tree in forest_11.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rf_predictions = forest_11.predict(X_train)\n",
    "train_rf_probs = forest_11.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest_11.predict(X_test)\n",
    "rf_probs = forest_11.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_11_adv = mean_absolute_error(y_test_2_11,y_pred_rf_2_11_adv)\n",
    "#MAE_mod=mean_absolute_percentage_error_modify(y_test_2_8,y_pred_rf_2_8)\n",
    "MAPE_11_adv=mean_absolute_percentage_error(y_test_2_11,y_pred_rf_2_11_adv)\n",
    "print(f'Der MAE für Blechkuchen beträgt:{MAE_11_adv}')\n",
    "print(f'Der MAPE für Blechkuchen beträgt:{MAPE_11_adv}')\n",
    "df_results_Random_Forest.loc['23',:] = ['Random_Forest-Basis','Blechkuchen',MAE_11_adv,MAPE_11_adv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weihnachtsartikel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_9=train_2.iloc[:,np.r_[26,42,22,69,70]]\n",
    "X_test_2_9=test_2.iloc[:,np.r_[26,42,22,69,70]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_12=train_2.iloc[:,np.r_[14:47,69,70]]\n",
    "X_test_2_12=test_2.iloc[:,np.r_[14:47,60,70]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_12\n",
    "X_test=X_test_2_12\n",
    "y_train=y_train_2_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest_12 = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest_12.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_12_adv = forest_12.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_tree in forest_12.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rf_predictions = forest_12.predict(X_train)\n",
    "train_rf_probs = forest_12.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest_12.predict(X_test)\n",
    "rf_probs = forest_12.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_12_adv = mean_absolute_error(y_test_2_12,y_pred_rf_2_12_adv)\n",
    "MAPE_12_adv=mean_absolute_percentage_error(y_test_2_12,y_pred_rf_2_12_adv)\n",
    "print(f'Der MAE für Weihnachtsartikel beträgt:{MAE_12_adv}')\n",
    "print(f'Der MAPE für Weihnachtsartikel beträgt:{MAPE_12_adv}')\n",
    "df_results_Random_Forest.loc['24',:] = ['Random_Forest-Basis','Weihnachtsartikel',MAE_12,MAPE_12_adv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Model with adjusted Trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**\n",
    "- `I check if the replacing of the zero-Sales has an impact to the predictions. I do it first for all articlegroups which belongs to Brötchen. `\n",
    "- `There is no significant impact so I skip to this and have a lot to feature importance of the different labels. `\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brötchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2['Brötchen']=train_2['Brötchen'].apply(lambda x: x if x> 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2['Brötchen'].fillna(method='ffill',inplace=True)\n",
    "train_2['Brötchen'].fillna(method='bfill',inplace=True)\n",
    "train_2['Brötchen']=train_2['Brötchen'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_6=train_2.iloc[:,np.r_[14,16,17,19,21,22,25:47,58,70,71]]\n",
    "X_test_2_6=test_2.iloc[:,np.r_[14,16,17,19,21,22,25:47,58,70,71]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_6\n",
    "X_test=X_test_2_6\n",
    "y_train=train_2['Brötchen']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest = RandomForestClassifier(random_state = 0)\n",
    "\n",
    "# Step 2: Train the model on the data\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_6_adv = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]\n",
    "\n",
    "for ind_tree in forest.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rf_predictions = forest.predict(X_train)\n",
    "train_rf_probs = forest.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest.predict(X_test)\n",
    "rf_probs = forest.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_6_adv = mean_absolute_error(y_test_2_6,y_pred_rf_2_6_adv)\n",
    "MAPE_6_adv=mean_absolute_percentage_error(y_test_2_6,y_pred_rf_2_6_adv)\n",
    "print(f'Der MAE für Brötchen beträgt:{MAE_6_adv}')\n",
    "print(f'Der MAPE für Brötchen beträgt:{MAPE_6_adv}')\n",
    "df_results_Random_Forest.loc['54',:] = ['Random_Forest-Advanced_Closedrepl','Brötchen',MAE_6_adv,MAPE_6_adv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Süsse Brötchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2['Süsse_Brötchen']=train_2['Süsse_Brötchen'].apply(lambda x: x if x> 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2['Süsse_Brötchen'].fillna(method='ffill',inplace=True)\n",
    "train_2['Süsse_Brötchen'].fillna(method='bfill',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2['Süsse_Brötchen']=train_2['Süsse_Brötchen'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_7=train_2.iloc[:,np.r_[14,16,17,19,21,22,25:47,60,70,71]]\n",
    "X_test_2_7=test_2.iloc[:,np.r_[14,16,17,19,21,22,25:47,60,70,71]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_7\n",
    "X_test=X_test_2_7\n",
    "y_train=train_2['Süsse_Brötchen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_7_adv = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]\n",
    "\n",
    "for ind_tree in forest.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rf_predictions = forest.predict(X_train)\n",
    "train_rf_probs = forest.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest.predict(X_test)\n",
    "rf_probs = forest.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_7_adv = mean_absolute_error(y_test_2_7,y_pred_rf_2_7_adv)\n",
    "MAPE_7_adv=mean_absolute_percentage_error(y_test_2_7,y_pred_rf_2_7_adv)\n",
    "print(f'Der MAE für Süsse Brötchen beträgt:{MAE_7_adv}')\n",
    "print(f'Der MAPE für Süsse Brötchen beträgt:{MAPE_7_adv}')\n",
    "df_results_Random_Forest.loc['55',:] = ['Random_Forest-Advanced_Closedrepl','Süsse Brötchen',MAE_7_adv,MAPE_7_adv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Herzhafte Brötchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2['Herzhafte_Brötchen']=train_2['Herzhafte_Brötchen'].apply(lambda x: x if x> 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2['Herzhafte_Brötchen'].fillna(method='ffill',inplace=True)\n",
    "train_2['Herzhafte_Brötchen'].fillna(method='bfill',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2['Herzhafte_Brötchen']=train_2['Herzhafte_Brötchen'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_8=train_2.iloc[:,np.r_[14,16,17,19,21,22,25:47,61,61]]\n",
    "X_test_2_8=test_2.iloc[:,np.r_[14,16,17,19,21,22,25:47,61,62]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_8=train_2.iloc[:,np.r_[14:47]]\n",
    "X_test_2_8=test_2.iloc[:,np.r_[14:47]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_2_8\n",
    "X_test=X_test_2_8\n",
    "y_train=train_2['Herzhafte_Brötchen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make an instance of the Model\n",
    "forest = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train the model on the data\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: predict the response for test data\n",
    "y_pred_rf_2_8_adv = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "n_features=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_tree in forest.estimators_:\n",
    "    n_features.append(ind_tree.tree_.n_features)\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of features {int(np.mean(n_features))}')\n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rf_predictions = forest.predict(X_train)\n",
    "train_rf_probs = forest.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = forest.predict(X_test)\n",
    "rf_probs = forest.predict_proba(X_test)[:, 1]\n",
    "\n",
    "MAE_8_adv = mean_absolute_error(y_test_2_8,y_pred_rf_2_8_adv)\n",
    "#MAE_mod=mean_absolute_percentage_error_modify(y_test_2_8,y_pred_rf_2_8)\n",
    "MAPE_8_adv=mean_absolute_percentage_error(y_test_2_8,y_pred_rf_2_8_adv)\n",
    "print(f'Der MAE für Herzhafte_Brötchen beträgt:{MAE_8_adv}')\n",
    "#print(f'Der MAE_mod für Brötchen beträgt:{MAE_mod}')\n",
    "print(f'Der MAPE für Herzhafte_Brötchen beträgt:{MAPE_8_adv}')\n",
    "df_results_Random_Forest.loc['56',:] = ['Random_Forest-Closedrepl','Herzhafte_Brötchen',MAE_8,MAPE_8_adv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**\n",
    "- `So lets have a lot to feature importance. Some of the results are rather surprising. A couple of article groups seems to be dependent of the sales figures of Weizenbrot.`\n",
    "- `So I decide to fit the belonging models again and consider this features.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weizenbrot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_2_1 = forest_1.feature_importances_\n",
    "features = train_2.iloc[:,14:].columns\n",
    "indices = np.argsort(imp_2_1)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.title('Feature Importances for Weizenbrot')\n",
    "plt.barh(range(len(indices[17:])), imp_2_1[indices[17:]], color='b', align='center')\n",
    "plt.yticks(range(len(indices[17:])), [features[i] for i in indices[17:]])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mischbrot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_2_2 = forest_2.feature_importances_\n",
    "features = train_2.iloc[:,14:].columns\n",
    "indices = np.argsort(imp_2_2)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.title('Feature Importances for Mischbrot')\n",
    "plt.barh(range(len(indices[17:])), imp_2_2[indices[17:]], color='b', align='center')\n",
    "plt.yticks(range(len(indices[17:])), [features[i] for i in indices[17:]])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vollkornbrot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_2_3 = forest_3.feature_importances_\n",
    "features = train_2.iloc[:,14:].columns\n",
    "indices = np.argsort(imp_2_3)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.title('Feature Importances for Vollkornbrot')\n",
    "plt.barh(range(len(indices[17:])), imp_2_3[indices[17:]], color='b', align='center')\n",
    "plt.yticks(range(len(indices[17:])), [features[i] for i in indices[17:]])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spezialbrot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_2_4 = forest_4.feature_importances_\n",
    "features = train_2.iloc[:,14:].columns\n",
    "indices = np.argsort(imp_2_4)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.title('Feature Importances for Spezialbrot')\n",
    "plt.barh(range(len(indices[17:])), imp_2_4[indices[17:]], color='b', align='center')\n",
    "plt.yticks(range(len(indices[17:])), [features[i] for i in indices[17:]])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stangenbrote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_2_5 = forest_5.feature_importances_\n",
    "features = train_2.iloc[:,14:].columns\n",
    "indices = np.argsort(imp_2_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.title('Feature Importances for Stangenbrote')\n",
    "plt.barh(range(len(indices[25:])), imp_2_5[indices[25:]], color='b', align='center')\n",
    "plt.yticks(range(len(indices[25:])), [features[i] for i in indices[25:]])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brötchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_2_6 = forest_6.feature_importances_\n",
    "features = train_2.iloc[:,14:].columns\n",
    "indices = np.argsort(imp_2_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.title('Feature Importances for Brötchen')\n",
    "plt.barh(range(len(indices[17:])), imp_2_6[indices[17:]], color='b', align='center')\n",
    "plt.yticks(range(len(indices[17:])), [features[i] for i in indices[17:]])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Süsse Brötchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_2_7 = forest_7.feature_importances_\n",
    "features = train_2.iloc[:,14:].columns\n",
    "indices = np.argsort(imp_2_7)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.title('Feature Importances for Süsse Brötchen')\n",
    "plt.barh(range(len(indices[17:])), imp_2_7[indices[17:]], color='b', align='center')\n",
    "plt.yticks(range(len(indices[17:])), [features[i] for i in indices[17:]])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Herzhafte Brötchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_2_8 = forest_8.feature_importances_\n",
    "features = train_2.iloc[:,14:].columns\n",
    "indices = np.argsort(imp_2_8)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.title('Feature Importances for Herzhafte Brötchen')\n",
    "plt.barh(range(len(indices[17:])), imp_2_8[indices[17:]], color='b', align='center')\n",
    "plt.yticks(range(len(indices[17:])), [features[i] for i in indices[17:]])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KonditoreiBlech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_2_9 = forest_9.feature_importances_\n",
    "features = train_2.iloc[:,14:47].columns\n",
    "indices = np.argsort(imp_2_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.title('Feature Importances for KonditoreiBlech')\n",
    "plt.barh(range(len(indices[25:])), imp_2_9[indices[17:]], color='b', align='center')\n",
    "plt.yticks(range(len(indices[25:])), [features[i] for i in indices[17:]])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stückgebäck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_2_10 = forest_10.feature_importances_\n",
    "features = train_2.iloc[:,14:].columns\n",
    "indices = np.argsort(imp_2_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.title('Feature Importances for Stückgebäck')\n",
    "plt.barh(range(len(indices[25:])), imp_2_10[indices[25:]], color='b', align='center')\n",
    "plt.yticks(range(len(indices[25:])), [features[i] for i in indices[25:]])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blechkuchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_2_11 = forest_11.feature_importances_\n",
    "features = train_2.iloc[:,14:].columns\n",
    "indices = np.argsort(imp_2_11)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.title('Feature Importances for Blechkuchen')\n",
    "plt.barh(range(len(indices[25:])), imp_2_11[indices[25:]], color='b', align='center')\n",
    "plt.yticks(range(len(indices[25:])), [features[i] for i in indices[25:]])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weihnachtsartikel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_2_12 = forest_12.feature_importances_\n",
    "features = train_2.iloc[:,14:].columns\n",
    "indices = np.argsort(imp_2_12)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.title('Feature Importances for Weihnachtsartikel')\n",
    "plt.barh(range(len(indices[25:])), imp_2_12[indices[25:]], color='b', align='center')\n",
    "plt.yticks(range(len(indices[25:])), [features[i] for i in indices[25:]])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further optimazation due to performance plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Models to consider?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison for the total sales of the store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_2.iloc[:,14:]\n",
    "y_train=train_2['Gesamt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "#models.append(('LR', LinearRegression()))\n",
    "models.append(('NN', MLPRegressor(solver = 'lbfgs')))  #neural network\n",
    "models.append(('KNN', KNeighborsRegressor())) \n",
    "models.append(('RF', RandomForestRegressor(n_estimators = 10))) # Ensemble method - collection of many decision trees\n",
    "models.append(('SVR', SVR(gamma='auto'))) # kernel = linear\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    # TimeSeries Cross validation\n",
    " tscv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    " cv_results = cross_val_score(model, X_train, y_train, cv=tscv, scoring='r2')\n",
    " results.append(cv_results)\n",
    " names.append(name)\n",
    " print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
    "    \n",
    "# Compare Algorithms\n",
    "plt.boxplot(results, labels=names)\n",
    "plt.title('Algorithm Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "#models.append(('LR', LinearRegression()))\n",
    "models.append(('NN', MLPRegressor(solver = 'lbfgs')))  #neural network\n",
    "models.append(('KNN', KNeighborsRegressor())) \n",
    "models.append(('RF', RandomForestRegressor(n_estimators = 10))) # Ensemble method - collection of many decision trees\n",
    "models.append(('SVR', SVR(gamma='auto'))) # kernel = linear\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    # TimeSeries Cross validation\n",
    " tscv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    " cv_results = cross_val_score(model, X_train, train_2['Brötchen'], cv=tscv, scoring='r2')\n",
    " results.append(cv_results)\n",
    " names.append(name)\n",
    " print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
    "    \n",
    "# Compare Algorithms\n",
    "plt.boxplot(results, labels=names)\n",
    "plt.title('Algorithm Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_R=train_2.iloc[:,14:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train_2['Brötchen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sktime.datasets import load_arrow_head  # univariate dataset\n",
    "from sktime.transformers.series_as_features.rocket import Rocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocket = Rocket(num_kernels=10000, random_state=111) \n",
    "rocket.fit(X_train_R)\n",
    "X_train_transform = rocket.transform(X_train_R)\n",
    "X_train_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "classifier.fit(X_train_transform, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transform = rocket.transform(X_test)\n",
    "classifier.score(X_test_transform, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "527.778px",
    "left": "50px",
    "top": "110.052px",
    "width": "282.778px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
